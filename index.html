<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI History Timeline - Ultra Smooth Experience</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #0a0a0a;
            color: #ffffff;
            overflow-x: hidden;
            position: relative;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        
        /* Performance optimizations */
        .gpu-accelerated {
            transform: translateZ(0);
            will-change: transform;
            backface-visibility: hidden;
            perspective: 1000px;
        }
        
        /* Simplified background */
        .background-gradient {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: 
                radial-gradient(circle at 20% 50%, rgba(33, 150, 243, 0.15) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(255, 87, 34, 0.1) 0%, transparent 50%),
                #0a0a0a;
            z-index: -1;
        }
        
        /* Minimal particles for performance */
        .particles {
            position: fixed;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: 1;
        }
        
        .particle {
            position: absolute;
            width: 4px;
            height: 4px;
            background: rgba(100, 181, 246, 0.6);
            border-radius: 50%;
            bottom: -10px;
        }
        
        /* Hero section */
        .hero {
            height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            position: relative;
            z-index: 2;
        }
        
        .hero h1 {
            font-size: clamp(3rem, 8vw, 5rem);
            font-weight: 700;
            text-align: center;
            background: linear-gradient(135deg, #2196F3 0%, #64B5F6 50%, #FF5722 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 20px;
            transform: translateZ(0);
        }
        
        .hero-subtitle {
            font-size: clamp(1rem, 3vw, 1.5rem);
            color: #64B5F6;
            opacity: 0.8;
            text-align: center;
            margin-bottom: 10px;
        }
        
        .scroll-indicator {
            position: absolute;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            opacity: 0.6;
            transition: opacity 0.3s ease;
        }
        
        .scroll-indicator:hover {
            opacity: 1;
        }
        
        /* Timeline sections */
        .timeline-section {
            position: relative;
            padding: 80px 0;
            z-index: 10;
        }
        
        .section-title {
            font-size: clamp(2rem, 5vw, 3.5rem);
            text-align: center;
            margin-bottom: 60px;
            color: #64B5F6;
            font-weight: 700;
        }
        
        .timeline-container {
            max-width: 1200px;
            margin: 0 auto;
            position: relative;
            padding: 0 40px;
        }
        
        /* Optimized timeline line */
        .timeline-line {
            position: absolute;
            left: 50%;
            top: 0;
            bottom: 0;
            width: 2px;
            background: linear-gradient(to bottom, 
                transparent 0%, 
                #2196F3 10%, 
                #2196F3 90%, 
                transparent 100%
            );
            transform: translateX(-50%);
        }
        
        /* Timeline items with optimized animations */
        .timeline-item {
            position: relative;
            margin-bottom: 80px;
            opacity: 0;
            transform: translateY(30px);
            transition: opacity 0.4s ease, transform 0.4s ease;
        }
        
        .timeline-item.visible {
            opacity: 1;
            transform: translateY(0);
        }
        
        .timeline-item:nth-child(even) {
            text-align: right;
            padding-right: 52%;
        }
        
        .timeline-item:nth-child(odd) {
            text-align: left;
            padding-left: 52%;
        }
        
        /* Simplified timeline dots */
        .timeline-dot {
            position: absolute;
            width: 24px;
            height: 24px;
            background: #2196F3;
            border: 3px solid #0a0a0a;
            border-radius: 50%;
            top: 5px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 2;
            transition: transform 0.2s ease;
        }
        
        .timeline-item:hover .timeline-dot {
            transform: translateX(-50%) scale(1.3);
        }
        
        .timeline-dot.major {
            width: 32px;
            height: 32px;
            background: #FF5722;
        }
        
        /* Optimized content cards */
        .timeline-content {
            background: rgba(20, 20, 20, 0.9);
            padding: 25px;
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            position: relative;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
            transform: translateZ(0);
        }
        
        .timeline-content:hover {
            transform: translateY(-4px);
            box-shadow: 0 12px 24px rgba(0, 0, 0, 0.4);
        }
        
        /* Simplified date badges */
        .timeline-date {
            display: inline-block;
            background: #1a1a1a;
            color: #64B5F6;
            padding: 6px 16px;
            border-radius: 20px;
            font-weight: 600;
            font-size: 13px;
            margin-bottom: 12px;
            border: 1px solid #2196F3;
        }
        
        .timeline-date.future {
            border-color: #8B5CF6;
            color: #8B5CF6;
        }
        
        .timeline-date.reflection {
            border-color: #10B981;
            color: #10B981;
        }
        
        .timeline-title {
            font-size: 22px;
            font-weight: 600;
            margin-bottom: 12px;
            color: #ffffff;
            line-height: 1.3;
        }
        
        .timeline-description {
            color: #b0b0b0;
            line-height: 1.7;
            font-size: 15px;
        }
        
        .timeline-tech {
            margin-top: 12px;
            font-size: 13px;
            color: #64B5F6;
            font-style: italic;
            padding-top: 12px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        /* Simplified era separators */
        .era-separator {
            position: relative;
            height: 200px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 100px 0;
        }
        
        .era-separator::before {
            content: '';
            position: absolute;
            width: 80%;
            height: 1px;
            background: linear-gradient(90deg, transparent, #2196F3, transparent);
            opacity: 0.5;
        }
        
        .era-title {
            font-size: clamp(1.5rem, 4vw, 2.5rem);
            font-weight: 600;
            text-align: center;
            padding: 15px 30px;
            background: #0a0a0a;
            border: 2px solid #2196F3;
            border-radius: 40px;
            position: relative;
            z-index: 2;
        }
        
        /* Footer */
        .footer {
            text-align: center;
            padding: 80px 20px 40px;
            color: #64B5F6;
            font-size: 1.1em;
            position: relative;
        }
        
        /* Responsive */
        @media (max-width: 768px) {
            .timeline-item:nth-child(even),
            .timeline-item:nth-child(odd) {
                padding: 0 20px 0 60px;
                text-align: left;
            }
            
            .timeline-line {
                left: 30px;
            }
            
            .timeline-dot {
                left: 30px;
            }
            
            .timeline-content {
                padding: 20px;
            }
        }
        
        /* Reduced motion preferences */
        @media (prefers-reduced-motion: reduce) {
            * {
                animation: none !important;
                transition: none !important;
            }
        }
    </style>
</head>
<body>
    <!-- Simplified background -->
    <div class="background-gradient"></div>
    
    <!-- Minimal particles -->
    <div class="particles" id="particles"></div>
    
    <!-- Hero Section -->
    <div class="hero">
        <h1 class="gpu-accelerated">The Evolution of AI</h1>
        <p class="hero-subtitle">From Ancient Logic to Modern Intelligence</p>
        <p class="hero-subtitle">2,400 Years of Human Ingenuity</p>
        <div class="scroll-indicator">
            <svg width="30" height="30" viewBox="0 0 30 30">
                <path d="M15 8 L15 22 M9 16 L15 22 L21 16" stroke="#64B5F6" stroke-width="2" fill="none"/>
            </svg>
        </div>
    </div>
    
    <!-- Ancient Foundations Era -->
    <div class="era-separator">
        <h2 class="era-title">Ancient Foundations to Early Computing</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">384 BCE</span>
                    <h3 class="timeline-title">Aristotle's Formal Logic</h3>
                    <p class="timeline-description">
                        "A single assertion must always either affirm or deny a single predicate of a single subject." 
                        Aristotle establishes formal reasoning and syllogistic logic, creating the binary foundation that would eventually underpin all digital computing.
                    </p>
                    <div class="timeline-tech">Contribution: Binary logic, formal reasoning systems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">279 BCE</span>
                    <h3 class="timeline-title">Stoic Propositional Logic</h3>
                    <p class="timeline-description">
                        Chrysippus of Soli develops propositional logic focusing on relationships between complete statements. 
                        Introduces conditional reasoning ("if-then" structures) remarkably similar to modern Boolean logic.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">820 CE</span>
                    <h3 class="timeline-title">Al-Khwarizmi's Algorithms</h3>
                    <p class="timeline-description">
                        Muhammad ibn Musa al-Khwarizmi introduces systematic, step-by-step problem-solving procedures. 
                        The word "algorithm" derives from his name, establishing the conceptual framework for all computational processes.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1275</span>
                    <h3 class="timeline-title">Ramon Llull's Ars Magna</h3>
                    <p class="timeline-description">
                        Creates the first mechanical reasoning device using rotating paper disks to generate logical combinations. 
                        Considered the first attempt at mechanizing thought processes.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1642</span>
                    <h3 class="timeline-title">Pascal's Calculator</h3>
                    <p class="timeline-description">
                        Blaise Pascal builds the first mechanical calculator, demonstrating that machines could perform mathematical reasoning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1679</span>
                    <h3 class="timeline-title">Leibniz's Binary System</h3>
                    <p class="timeline-description">
                        Gottfried Wilhelm Leibniz develops the modern binary number system (0 and 1), 
                        inspired by the I Ching. This mathematical representation becomes the foundation 
                        for all digital computers.
                    </p>
                    <div class="timeline-tech">Impact: Enabled digital representation of information</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1804</span>
                    <h3 class="timeline-title">Jacquard Loom</h3>
                    <p class="timeline-description">
                        Joseph Marie Jacquard invents a loom controlled by punched cards, creating complex patterns automatically. 
                        First practical programmable machine, directly inspiring Babbage's Analytical Engine.
                    </p>
                    <div class="timeline-tech">Innovation: Stored programs via punched cards</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1837</span>
                    <h3 class="timeline-title">Babbage's Analytical Engine</h3>
                    <p class="timeline-description">
                        Charles Babbage designs the first Turing-complete mechanical computer. 
                        Ada Lovelace writes the first algorithm and envisions computers beyond mere calculation.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1854</span>
                    <h3 class="timeline-title">Boolean Algebra</h3>
                    <p class="timeline-description">
                        George Boole publishes "An Investigation of the Laws of Thought," introducing Boolean algebra with AND, OR, NOT operations. 
                        This mathematical formalization of logic would later be recognized as the foundation of digital circuit design.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of all modern computing</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1879</span>
                    <h3 class="timeline-title">Frege's Predicate Logic</h3>
                    <p class="timeline-description">
                        Gottlob Frege creates the first complete system of predicate logic in his Begriffsschrift, 
                        providing the rigorous formal framework necessary for automated reasoning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1880</span>
                    <h3 class="timeline-title">Venn Diagrams</h3>
                    <p class="timeline-description">
                        John Venn introduces Venn diagrams for visualizing set theory relationships, 
                        making logical relationships more intuitive and accessible.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1910-13</span>
                    <h3 class="timeline-title">Principia Mathematica</h3>
                    <p class="timeline-description">
                        Whitehead and Russell attempt to derive all mathematics from logical principles. 
                        This monumental work makes AI seem feasible by suggesting all reasoning could be formalized.
                    </p>
                    <div class="timeline-tech">Significance: Inspired the quest to mechanize thought</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1936</span>
                    <h3 class="timeline-title">Turing Machine</h3>
                    <p class="timeline-description">
                        Alan Turing introduces the theoretical Turing Machine, proving that a simple device manipulating symbols 
                        could perform any computation. Establishes the theoretical foundation of computer science.
                    </p>
                    <div class="timeline-tech">Legacy: Defined the limits of mechanical computation</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Birth of AI Era -->
    <div class="era-separator">
        <h2 class="era-title">The Birth of Artificial Intelligence</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1942</span>
                    <h3 class="timeline-title">Asimov's Three Laws of Robotics</h3>
                    <p class="timeline-description">
                        Isaac Asimov introduces the Three Laws in "Runaround": robots must not harm humans, must obey orders, and must preserve themselves. 
                        These fictional laws profoundly influence real AI ethics discussions for decades.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for AI ethics debates</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1943</span>
                    <h3 class="timeline-title">McCulloch-Pitts Neuron</h3>
                    <p class="timeline-description">
                        Warren McCulloch and Walter Pitts publish "A Logical Calculus of Ideas Immanent in Nervous Activity," 
                        creating the first mathematical model of artificial neurons. This bridges biology and computation.
                    </p>
                    <div class="timeline-tech">Innovation: First artificial neuron model</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1948</span>
                    <h3 class="timeline-title">Wiener's Cybernetics</h3>
                    <p class="timeline-description">
                        Norbert Wiener publishes "Cybernetics: Or Control and Communication in the Animal and the Machine," 
                        establishing the theoretical framework for feedback control systems and inspiring generations of AI researchers.
                    </p>
                    <div class="timeline-tech">Impact: Foundational theory for intelligent systems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1948</span>
                    <h3 class="timeline-title">Shannon's Information Theory</h3>
                    <p class="timeline-description">
                        Claude Shannon establishes information theory, providing the mathematical framework for digital communication 
                        and establishing the bit as the fundamental unit of information.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1949</span>
                    <h3 class="timeline-title">Hebb's Rule</h3>
                    <p class="timeline-description">
                        Donald Hebb publishes "The Organization of Behavior," proposing that "neurons that fire together wire together." 
                        This principle becomes fundamental to how neural networks learn through synaptic strengthening.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for all neural network learning algorithms</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1950</span>
                    <h3 class="timeline-title">Turing Test</h3>
                    <p class="timeline-description">
                        Alan Turing proposes the "Imitation Game" in "Computing Machinery and Intelligence," 
                        establishing a practical test for machine intelligence and the philosophical framework that guides AI research.
                    </p>
                    <div class="timeline-tech">Legacy: Defined the goal of conversational AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1951</span>
                    <h3 class="timeline-title">SNARC - First Neural Network Machine</h3>
                    <p class="timeline-description">
                        Marvin Minsky creates the Stochastic Neural Analog Reinforcement Calculator, the first artificial neural network machine. 
                        Built with vacuum tubes, it simulates a rat finding its way through a maze using 40 artificial neurons.
                    </p>
                    <div class="timeline-tech">Components: Vacuum tubes, adjustable knobs for memory</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1952</span>
                    <h3 class="timeline-title">Grace Hopper's First Compiler</h3>
                    <p class="timeline-description">
                        Grace Hopper develops the A-0 compiler, the first program to translate human-readable code into machine language. 
                        This breakthrough enables higher-level programming languages essential for AI development.
                    </p>
                    <div class="timeline-tech">Legacy: Made programming accessible, enabling AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1952-59</span>
                    <h3 class="timeline-title">Arthur Samuel's Machine Learning</h3>
                    <p class="timeline-description">
                        Creates a checkers-playing program that improves through self-play. 
                        Coins the term "machine learning" in 1959 and demonstrates that computers can learn from experience.
                    </p>
                    <div class="timeline-tech">Achievement: First self-learning program</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1953</span>
                    <h3 class="timeline-title">Bellman Equations</h3>
                    <p class="timeline-description">
                        Richard Bellman publishes "An Introduction to the Theory of Dynamic Programming," establishing the mathematical foundation 
                        for reinforcement learning and optimal control theory that remains central to AI today.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of modern reinforcement learning</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1956</span>
                    <h3 class="timeline-title">Dartmouth Conference - Birth of AI</h3>
                    <p class="timeline-description">
                        Organized by McCarthy, Minsky, Shannon, and Rochester. Formally establishes AI as a field with the goal to 
                        "simulate every aspect of learning or any other feature of intelligence." The Logic Theorist, first AI program, is presented.
                    </p>
                    <div class="timeline-tech">Significance: AI becomes an academic discipline</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1957</span>
                    <h3 class="timeline-title">Perceptron</h3>
                    <p class="timeline-description">
                        Frank Rosenblatt develops the Perceptron, the first practical neural network with learning capability 
                        through adjustable weights and error-based learning. Built as a hardware machine, not just theory.
                    </p>
                    <div class="timeline-tech">Innovation: First implemented learning algorithm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1957</span>
                    <h3 class="timeline-title">General Problem Solver</h3>
                    <p class="timeline-description">
                        Newell and Simon create GPS, using abstract problem representation and flexible operators 
                        to tackle problems across various domains, unlike the domain-specific Logic Theorist.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1958</span>
                    <h3 class="timeline-title">LISP Programming Language</h3>
                    <p class="timeline-description">
                        John McCarthy creates LISP, which becomes the dominant programming language for AI development 
                        for the next several decades.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1958</span>
                    <h3 class="timeline-title">Mechanisation of Thought Processes Conference</h3>
                    <p class="timeline-description">
                        First international AI conference in England predates even the term "artificial intelligence." 
                        Brings together early pioneers and establishes international collaboration in the field.
                    </p>
                    <div class="timeline-tech">Significance: AI becomes international</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1959</span>
                    <h3 class="timeline-title">MIT AI Lab Founded</h3>
                    <p class="timeline-description">
                        Marvin Minsky and John McCarthy establish the MIT AI Lab, creating one of the twin pillars 
                        of American AI research that would train generations of AI researchers.
                    </p>
                    <div class="timeline-tech">Impact: Legitimized AI as academic discipline</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1959</span>
                    <h3 class="timeline-title">Selfridge's Pandemonium</h3>
                    <p class="timeline-description">
                        Oliver Selfridge proposes the Pandemonium architecture for pattern recognition, 
                        using parallel processing "demons" that inspired later neural network designs.
                    </p>
                    <div class="timeline-tech">Innovation: Early parallel processing concept</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1960</span>
                    <h3 class="timeline-title">ADALINE/MADALINE</h3>
                    <p class="timeline-description">
                        Widrow & Hoff introduce continuous outputs and the least-mean-square learning rule, 
                        providing more robust learning than the perceptron.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1960s</span>
                    <h3 class="timeline-title">John Holland's Genetic Algorithms</h3>
                    <p class="timeline-description">
                        Develops evolutionary computation inspired by natural selection. Genetic algorithms 
                        evolve solutions through mutation, crossover, and selection, pioneering bio-inspired AI.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of evolutionary computing</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1963</span>
                    <h3 class="timeline-title">Stanford AI Lab Founded</h3>
                    <p class="timeline-description">
                        John McCarthy establishes SAIL after leaving MIT, creating the second pillar 
                        of American AI research and fostering West Coast AI innovation.
                    </p>
                    <div class="timeline-tech">Notable work: Computer vision, robotics, natural language</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1964-67</span>
                    <h3 class="timeline-title">ELIZA Chatbot</h3>
                    <p class="timeline-description">
                        Joseph Weizenbaum creates ELIZA, which rephrases user input to simulate conversation. 
                        Despite its simplicity, it occasionally fools people into thinking it's human, 
                        leading to the concept of the "ELIZA Effect."
                    </p>
                    <div class="timeline-tech">Method: Pattern matching and keyword substitution</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1965</span>
                    <h3 class="timeline-title">Fuzzy Logic</h3>
                    <p class="timeline-description">
                        Lotfi Zadeh introduces fuzzy set theory, allowing degrees of truth rather than binary true/false. 
                        Revolutionizes control systems and enables AI to handle uncertainty and imprecision.
                    </p>
                    <div class="timeline-tech">Applications: Industrial control, consumer electronics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1965</span>
                    <h3 class="timeline-title">DENDRAL Expert System</h3>
                    <p class="timeline-description">
                        First expert system for identifying molecular structures. 
                        Pioneers the use of domain-specific knowledge in AI systems.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1965</span>
                    <h3 class="timeline-title">Robinson's Resolution Principle</h3>
                    <p class="timeline-description">
                        J. Alan Robinson introduces resolution-based automated theorem proving, 
                        providing a complete and mechanizable inference rule for first-order logic.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of logic programming and Prolog</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1966-72</span>
                    <h3 class="timeline-title">Shakey the Robot</h3>
                    <p class="timeline-description">
                        SRI International develops Shakey, the first mobile robot to reason about its actions. 
                        Integrates computer vision, navigation, and planning in a single system, pioneering 
                        autonomous robotics.
                    </p>
                    <div class="timeline-tech">Innovations: STRIPS planner, A* search algorithm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1969</span>
                    <h3 class="timeline-title">Perceptrons Book - Beginning of AI Winter</h3>
                    <p class="timeline-description">
                        Minsky and Papert publish "Perceptrons," criticizing single-layer neural networks' limitations (like XOR problem). 
                        This effectively halts neural network research for over a decade, contributing to the first AI Winter.
                    </p>
                    <div class="timeline-tech">Impact: Neural network funding dried up until 1980s</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1970</span>
                    <h3 class="timeline-title">SHRDLU Natural Language Understanding</h3>
                    <p class="timeline-description">
                        Terry Winograd creates SHRDLU, demonstrating sophisticated natural language understanding in a limited "blocks world" domain. 
                        Shows AI can understand context and execute complex commands.
                    </p>
                    <div class="timeline-tech">Innovation: Context-aware language processing</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- AI Winter and Revival Era -->
    <div class="era-separator">
        <h2 class="era-title">AI Winter and Neural Network Revival</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1970</span>
                    <h3 class="timeline-title">Seppo Linnainmaa's Automatic Differentiation</h3>
                    <p class="timeline-description">
                        Develops the "reverse mode of automatic differentiation" for analyzing computational rounding errors. 
                        This mathematical foundation would later become backpropagation.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1973</span>
                    <h3 class="timeline-title">LUNAR Natural Language System</h3>
                    <p class="timeline-description">
                        William Woods creates LUNAR for NASA, answering questions about moon rock samples brought back by Apollo. 
                        Achieves 90% accuracy on geologists' questions, proving practical NLP applications.
                    </p>
                    <div class="timeline-tech">Innovation: Domain-specific question answering</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1973-80</span>
                    <h3 class="timeline-title">First AI Winter</h3>
                    <p class="timeline-description">
                        DARPA cuts AI funding after Lighthill Report criticizes AI's failure to handle "combinatorial explosion." 
                        Combined with Minsky's critique of perceptrons, research stagnates. Many influential researchers quit the field.
                    </p>
                    <div class="timeline-tech">Causes: Overpromises, computational limitations, theoretical roadblocks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1974</span>
                    <h3 class="timeline-title">Paul Werbos - Backpropagation Discovery</h3>
                    <p class="timeline-description">
                        Discovers backpropagation algorithm in his PhD thesis, but it remains largely unnoticed 
                        until popularized by Rumelhart, Hinton, and Williams in 1986.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1976</span>
                    <h3 class="timeline-title">Physical Symbol System Hypothesis</h3>
                    <p class="timeline-description">
                        Allen Newell and Herbert Simon formally propose that "a physical symbol system has the necessary and sufficient means 
                        for general intelligent action." This hypothesis dominates AI research for decades, though later challenged by embodied cognition.
                    </p>
                    <div class="timeline-tech">Impact: Defined symbolic AI paradigm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1976</span>
                    <h3 class="timeline-title">MYCIN Expert System</h3>
                    <p class="timeline-description">
                        Stanford's MYCIN diagnoses blood infections with accuracy matching human specialists. 
                        First AI system to demonstrate expert-level performance in medicine, though never deployed due to ethical concerns.
                    </p>
                    <div class="timeline-tech">Impact: Proved AI could match human expertise in specific domains</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1976</span>
                    <h3 class="timeline-title">HARPY Speech Recognition</h3>
                    <p class="timeline-description">
                        Carnegie Mellon's HARPY achieves 1,011-word vocabulary with 95% accuracy, 
                        first system to meet DARPA's ambitious speech understanding goals.
                    </p>
                    <div class="timeline-tech">Method: Beam search through pronunciation graph</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1978</span>
                    <h3 class="timeline-title">GRASP Lab Founded by Ruzena Bajcsy</h3>
                    <p class="timeline-description">
                        Ruzena Bajcsy establishes the GRASP Lab at Penn, developing the concept of "active perception" 
                        in robotics and advancing computer vision research.
                    </p>
                    <div class="timeline-tech">Innovation: Active perception in robotics</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1979</span>
                    <h3 class="timeline-title">Kunihiko Fukushima's Neocognitron</h3>
                    <p class="timeline-description">
                        Japanese researcher Kunihiko Fukushima develops the Neocognitron, the first multilayer convolutional neural network 
                        with hierarchical feature extraction, presaging modern CNNs by decades.
                    </p>
                    <div class="timeline-tech">Innovation: First CNN architecture</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1980</span>
                    <h3 class="timeline-title">John Searle's Chinese Room</h3>
                    <p class="timeline-description">
                        Philosopher John Searle publishes "Minds, Brains, and Programs" introducing the Chinese Room thought experiment. 
                        Argues that computers manipulating symbols cannot truly understand, challenging strong AI claims.
                    </p>
                    <div class="timeline-tech">Impact: Most influential critique of computational consciousness</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1980</span>
                    <h3 class="timeline-title">Belle Chess Computer</h3>
                    <p class="timeline-description">
                        Bell Labs' Belle becomes first chess computer to achieve master rating. 
                        Custom hardware evaluates 160,000 positions per second, paving way for Deep Blue.
                    </p>
                    <div class="timeline-tech">Innovation: Specialized chess hardware</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1980s</span>
                    <h3 class="timeline-title">Expert Systems Boom - XCON</h3>
                    <p class="timeline-description">
                        Digital Equipment Corporation's XCON checks computer component compatibility, 
                        saving $25 million annually. Sparks expert system boom, demonstrating commercial AI viability.
                    </p>
                    <div class="timeline-tech">Lesson: Early commercial AI success</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1982</span>
                    <h3 class="timeline-title">Hopfield Networks</h3>
                    <p class="timeline-description">
                        John Hopfield creates networks with associative memory using energy-based dynamics. 
                        Can retrieve complete patterns from partial or noisy inputs. Marks the beginning of neural network revival.
                    </p>
                    <div class="timeline-tech">Innovation: Content-addressable memory in neural networks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1982</span>
                    <h3 class="timeline-title">Self-Organizing Maps</h3>
                    <p class="timeline-description">
                        Teuvo Kohonen develops SOMs for unsupervised learning and data visualization, 
                        inspired by how the brain organizes sensory information.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1982-92</span>
                    <h3 class="timeline-title">Japan's Fifth Generation Project</h3>
                    <p class="timeline-description">
                        Japan launches $850 million initiative to create intelligent computers using logic programming. 
                        Triggers international AI arms race with US and Europe. Despite technical achievements, 
                        fails to deliver on promises, contributing to second AI Winter.
                    </p>
                    <div class="timeline-tech">Impact: Changed global AI competition dynamics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1983</span>
                    <h3 class="timeline-title">SOAR Cognitive Architecture</h3>
                    <p class="timeline-description">
                        Laird, Newell, and Rosenbloom develop SOAR (State, Operator And Result) at CMU. 
                        A unified theory of cognition that models human problem-solving and learning through 
                        production rules and chunking. Still actively used for AI research today.
                    </p>
                    <div class="timeline-tech">Applications: Robotics, game AI, cognitive modeling</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1984</span>
                    <h3 class="timeline-title">CART Algorithm</h3>
                    <p class="timeline-description">
                        Breiman et al. introduce Classification and Regression Trees, 
                        providing a versatile tool for both classification and regression tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1984-present</span>
                    <h3 class="timeline-title">Cyc Project</h3>
                    <p class="timeline-description">
                        Doug Lenat launches ambitious effort to manually encode common sense knowledge. 
                        After 40 years and millions of assertions, highlights the difficulty of explicit knowledge representation 
                        that modern LLMs now learn implicitly.
                    </p>
                    <div class="timeline-tech">Lesson: Knowledge acquisition bottleneck</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1985</span>
                    <h3 class="timeline-title">Boltzmann Machines</h3>
                    <p class="timeline-description">
                        Hinton and Sejnowski introduce stochastic neural networks that can learn internal representations, 
                        using simulated annealing for optimization.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1985</span>
                    <h3 class="timeline-title">Connection Machine</h3>
                    <p class="timeline-description">
                        Danny Hillis develops the CM-1 with 65,536 processors working in parallel. 
                        Pioneers massively parallel computing for AI, influencing modern GPU architectures.
                    </p>
                    <div class="timeline-tech">Architecture: 65K processors, SIMD design</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1986</span>
                    <h3 class="timeline-title">Backpropagation Popularized</h3>
                    <p class="timeline-description">
                        Rumelhart, Hinton, and Williams publish "Learning Representations by Back-Propagating Errors" in Nature. 
                        Demonstrates that multi-layer networks can be effectively trained, overcoming the XOR problem 
                        and reigniting interest in neural networks.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for all modern deep learning</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1986</span>
                    <h3 class="timeline-title">Recurrent Neural Networks (RNNs)</h3>
                    <p class="timeline-description">
                        David Rumelhart refines Hopfield Networks into modern RNNs for sequence processing. 
                        Still used today for language translation, speech recognition, and NLP tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1986</span>
                    <h3 class="timeline-title">Subsumption Architecture</h3>
                    <p class="timeline-description">
                        Rodney Brooks at MIT introduces behavior-based robotics, rejecting symbolic AI for reactive systems. 
                        Enables robots to operate in real-world environments, revolutionizing robotics.
                    </p>
                    <div class="timeline-tech">Philosophy: Intelligence without representation</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1987</span>
                    <h3 class="timeline-title">NeurIPS Conference Founded</h3>
                    <p class="timeline-description">
                        First Neural Information Processing Systems conference held in Denver. 
                        Becomes the premier venue for machine learning research, now with 15,000+ attendees annually.
                    </p>
                    <div class="timeline-tech">Impact: Created global ML research community</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1987</span>
                    <h3 class="timeline-title">Adaptive Resonance Theory</h3>
                    <p class="timeline-description">
                        Grossberg and Carpenter develop ART networks that solve the stability-plasticity dilemma, 
                        allowing networks to learn new patterns without forgetting old ones.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1987-93</span>
                    <h3 class="timeline-title">Second AI Winter</h3>
                    <p class="timeline-description">
                        LISP machine market collapses overnight when standard workstations match their performance at fraction of cost. 
                        Expert systems prove brittle and expensive. Over 300 AI companies fail. 
                        Overpromises again lead to disillusionment.
                    </p>
                    <div class="timeline-tech">Lesson: Hype cycles damage long-term progress</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1988</span>
                    <h3 class="timeline-title">Moravec's Paradox</h3>
                    <p class="timeline-description">
                        Hans Moravec observes: "It is comparatively easy to make computers exhibit adult level performance on intelligence tests... 
                        and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility." 
                        This insight still shapes AI research priorities.
                    </p>
                    <div class="timeline-tech">Impact: Highlighted embodied cognition challenges</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1988</span>
                    <h3 class="timeline-title">Deep Thought Chess Computer</h3>
                    <p class="timeline-description">
                        Carnegie Mellon's Deep Thought defeats grandmaster Bent Larsen, 
                        first computer victory over grandmaster in tournament play. Precursor to Deep Blue.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1989</span>
                    <h3 class="timeline-title">Universal Approximation Theorem</h3>
                    <p class="timeline-description">
                        Cybenko proves that neural networks with one hidden layer can approximate any continuous function on compact sets. 
                        This mathematical foundation provides theoretical justification for deep learning's potential.
                    </p>
                    <div class="timeline-tech">Impact: Proved neural networks' theoretical power</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1989</span>
                    <h3 class="timeline-title">Q-Learning Algorithm</h3>
                    <p class="timeline-description">
                        Christopher Watkins introduces Q-learning in his PhD thesis "Learning from Delayed Rewards." 
                        Becomes cornerstone of reinforcement learning, enabling agents to learn optimal policies without environment models.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for game AI and robotics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1989</span>
                    <h3 class="timeline-title">LeNet-1</h3>
                    <p class="timeline-description">
                        Yann LeCun creates the first successful convolutional neural network for handwritten digit recognition. 
                        Banks later adopt LeNet-5 for check processing.
                    </p>
                    <div class="timeline-tech">Architecture: Convolution, pooling, fully connected layers</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Rise of Modern AI Era -->
    <div class="era-separator">
        <h2 class="era-title">The Rise of Modern AI</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1990s</span>
                    <h3 class="timeline-title">Honda P Series Robots</h3>
                    <p class="timeline-description">
                        Honda develops P1, P2, and P3 humanoid robots (130-210kg), predecessors to ASIMO. 
                        Demonstrates progress in robotics and AI integration for physical tasks.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1991</span>
                    <h3 class="timeline-title">ArXiv.org Founded</h3>
                    <p class="timeline-description">
                        Paul Ginsparg launches arXiv at Los Alamos, creating the first preprint server. 
                        Revolutionizes scientific communication by enabling immediate sharing of research, 
                        accelerating AI progress through rapid dissemination of ideas.
                    </p>
                    <div class="timeline-tech">Impact: Transformed how AI research is shared globally</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1992</span>
                    <h3 class="timeline-title">TD-Gammon - Revolutionary Self-Play Learning</h3>
                    <p class="timeline-description">
                        Gerald Tesauro at IBM creates TD-Gammon using temporal difference learning. Trained entirely through self-play, 
                        it discovers opening strategies unknown to human experts, revolutionizing professional backgammon. 
                        Demonstrates that AI can surpass human knowledge through self-improvement.
                    </p>
                    <div class="timeline-tech">Architecture: 3-layer network, 198 inputs, TD(λ) algorithm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1992</span>
                    <h3 class="timeline-title">Resilient Propagation (Rprop)</h3>
                    <p class="timeline-description">
                        Introduced as a robust training algorithm using only gradient signs, 
                        avoiding issues with gradient magnitudes in deep networks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1994</span>
                    <h3 class="timeline-title">Raj Reddy Wins Turing Award</h3>
                    <p class="timeline-description">
                        First person of Asian origin to win the Turing Award for pioneering work 
                        in speech recognition and AI systems, advancing global representation in AI.
                    </p>
                    <div class="timeline-tech">Contribution: Speech recognition, AI education</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1995</span>
                    <h3 class="timeline-title">Support Vector Machines</h3>
                    <p class="timeline-description">
                        Vapnik and Cortes formalize SVMs with the kernel trick for non-linear classification. 
                        Becomes dominant ML algorithm in late 1990s and early 2000s before deep learning.
                    </p>
                    <div class="timeline-tech">Innovation: Kernel methods for non-linear problems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1995</span>
                    <h3 class="timeline-title">LSTM Networks</h3>
                    <p class="timeline-description">
                        Hochreiter and Schmidhuber introduce Long Short-Term Memory networks to solve the vanishing gradient problem. 
                        Enables learning of long-term dependencies in sequences, revolutionizing sequence modeling.
                    </p>
                    <div class="timeline-tech">Applications: Language modeling, speech recognition, time series</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1997</span>
                    <h3 class="timeline-title">Deep Blue Defeats Kasparov</h3>
                    <p class="timeline-description">
                        IBM's Deep Blue becomes the first computer to defeat world chess champion Garry Kasparov 
                        under regular time controls. Marks a milestone in AI achieving superhuman performance in complex games.
                    </p>
                    <div class="timeline-tech">Method: Brute force search with sophisticated evaluation</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1997</span>
                    <h3 class="timeline-title">Affective Computing Founded</h3>
                    <p class="timeline-description">
                        Rosalind Picard publishes "Affective Computing," creating an entirely new field 
                        focused on giving computers the ability to recognize and respond to human emotions.
                    </p>
                    <div class="timeline-tech">Impact: Emotion AI, human-computer interaction</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1998</span>
                    <h3 class="timeline-title">LeNet-5 Deployed</h3>
                    <p class="timeline-description">
                        Banks widely adopt LeCun's LeNet-5 for automated check processing, 
                        one of the first commercial deployments of deep learning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1999</span>
                    <h3 class="timeline-title">Sony AIBO Robot Dog</h3>
                    <p class="timeline-description">
                        First consumer AI robot pet capable of face recognition, detecting smiles, 
                        and learning tricks. Shows AI entering consumer market.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2000</span>
                    <h3 class="timeline-title">Judea Pearl's Causality</h3>
                    <p class="timeline-description">
                        Publishes "Causality: Models, Reasoning, and Inference," revolutionizing how we understand 
                        cause and effect in AI and statistics. Wins 2011 Turing Award for this work.
                    </p>
                    <div class="timeline-tech">Impact: Causal inference in AI and science</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2000s</span>
                    <h3 class="timeline-title">High-Frequency Trading AI Revolution</h3>
                    <p class="timeline-description">
                        AI algorithms transform financial markets, executing millions of trades per second. 
                        By 2010, HFT accounts for over 50% of US equity trading volume, fundamentally changing market dynamics.
                    </p>
                    <div class="timeline-tech">Impact: Millisecond advantages worth millions</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2001</span>
                    <h3 class="timeline-title">Random Forests</h3>
                    <p class="timeline-description">
                        Leo Breiman introduces Random Forests, combining bagging with random feature selection 
                        for robust ensemble learning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2002</span>
                    <h3 class="timeline-title">iRobot Roomba</h3>
                    <p class="timeline-description">
                        First successful consumer robot vacuum, demonstrating practical AI 
                        for everyday household tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2003</span>
                    <h3 class="timeline-title">Graph Neural Networks Begin</h3>
                    <p class="timeline-description">
                        Gori, Monfardini, and Scarselli introduce early GNN concepts for processing 
                        graph-structured data, later becoming crucial for social networks and molecular modeling.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for modern GNN architectures</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2004</span>
                    <h3 class="timeline-title">DARPA Grand Challenge</h3>
                    <p class="timeline-description">
                        Autonomous vehicle competition spurring development in self-driving technology. 
                        No vehicle completes the course in first year, proving the difficulty of the task.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2005</span>
                    <h3 class="timeline-title">Stanley Wins DARPA Challenge</h3>
                    <p class="timeline-description">
                        Stanford's autonomous vehicle "Stanley" wins $2 million DARPA Grand Challenge, 
                        completing 132-mile desert course autonomously. Proves self-driving cars are possible.
                    </p>
                    <div class="timeline-tech">Impact: Launches autonomous vehicle revolution</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2005</span>
                    <h3 class="timeline-title">Boston Dynamics BigDog</h3>
                    <p class="timeline-description">
                        First quadruped robot capable of traversing rough terrain, carrying heavy loads. 
                        Beginning of practical legged robotics for real-world applications.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2006</span>
                    <h3 class="timeline-title">NVIDIA CUDA Platform</h3>
                    <p class="timeline-description">
                        NVIDIA releases CUDA, making GPU parallel processing accessible to developers. 
                        Creates the computational foundation that would enable the deep learning revolution.
                    </p>
                    <div class="timeline-tech">Impact: Made deep learning computationally feasible</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2006</span>
                    <h3 class="timeline-title">Netflix Prize Launches</h3>
                    <p class="timeline-description">
                        $1 million competition to improve movie recommendations advances collaborative filtering 
                        and sparks the modern era of data science competitions, inspiring platforms like Kaggle.
                    </p>
                    <div class="timeline-tech">Legacy: Democratized machine learning competitions</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2006</span>
                    <h3 class="timeline-title">Deep Learning Renaissance Begins</h3>
                    <p class="timeline-description">
                        Geoffrey Hinton et al. introduce Deep Belief Networks with layer-wise pre-training. 
                        Solves the vanishing gradient problem that had plagued deep networks, 
                        marking the beginning of the modern deep learning era.
                    </p>
                    <div class="timeline-tech">Breakthrough: Enables training of truly deep networks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2008</span>
                    <h3 class="timeline-title">Betterment Launches Robo-Advisors</h3>
                    <p class="timeline-description">
                        First robo-advisor democratizes investment management using AI algorithms. 
                        The sector will grow to manage hundreds of billions in assets.
                    </p>
                    <div class="timeline-tech">Impact: AI transforms financial services</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2008</span>
                    <h3 class="timeline-title">t-SNE Visualization</h3>
                    <p class="timeline-description">
                        Van der Maaten and Hinton introduce t-SNE for high-dimensional data visualization, 
                        becoming essential tool for understanding neural network representations.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2009</span>
                    <h3 class="timeline-title">ImageNet Dataset</h3>
                    <p class="timeline-description">
                        Fei-Fei Li creates ImageNet with 14 million labeled images across 21,000 categories. 
                        Provides the large-scale data needed to train deep neural networks effectively, catalyzing the deep learning revolution.
                    </p>
                    <div class="timeline-tech">Impact: Enabled breakthrough CNN architectures</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2010</span>
                    <h3 class="timeline-title">DeepMind Founded</h3>
                    <p class="timeline-description">
                        Demis Hassabis, Shane Legg, and Mustafa Suleyman found DeepMind, 
                        pioneering deep reinforcement learning years before AlphaGo. Google acquires for $650M in 2014.
                    </p>
                    <div class="timeline-tech">Focus: General artificial intelligence through RL</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2010</span>
                    <h3 class="timeline-title">ImageNet Challenge Begins</h3>
                    <p class="timeline-description">
                        Annual competition that would catalyze the deep learning revolution. 
                        Establishes CNNs as the dominant computer vision approach and drives rapid progress.
                    </p>
                    <div class="timeline-tech">Impact: Standardized benchmark for vision AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2010</span>
                    <h3 class="timeline-title">Theano Deep Learning Framework</h3>
                    <p class="timeline-description">
                        MILA releases Theano, one of the first frameworks for efficient deep learning. 
                        Pioneers automatic differentiation and GPU computation for neural networks.
                    </p>
                    <div class="timeline-tech">Legacy: Inspired TensorFlow and PyTorch</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Deep Learning Revolution Era -->
    <div class="era-separator">
        <h2 class="era-title">The Deep Learning Revolution</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2011</span>
                    <h3 class="timeline-title">Google Brain Founded</h3>
                    <p class="timeline-description">
                        Andrew Ng and Jeff Dean establish Google Brain. Their famous cat-recognition experiment 
                        using 16,000 processors proves the scalability of deep learning at unprecedented scale.
                    </p>
                    <div class="timeline-tech">Achievement: Unsupervised learning at scale</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2011</span>
                    <h3 class="timeline-title">IBM Watson Wins Jeopardy!</h3>
                    <p class="timeline-description">
                        Watson defeats champions Ken Jennings and Brad Rutter on national television ($77,147 vs $24,000 and $21,600). 
                        First system achieving champion-level open-domain question answering, bringing AI to mainstream attention.
                    </p>
                    <div class="timeline-tech">Architecture: 90 Power 750 servers, DeepQA software</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2012</span>
                    <h3 class="timeline-title">AlexNet Changes Everything</h3>
                    <p class="timeline-description">
                        Krizhevsky, Sutskever, and Hinton win ImageNet by huge margin using deep CNNs on GPUs. 
                        Uses ReLU activation, dropout, and data augmentation. Reduces error from 26.2% to 15.3%, 
                        sparking the deep learning boom.
                    </p>
                    <div class="timeline-tech">Key innovations: GPU training, ReLU, Dropout, parallel processing</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2012</span>
                    <h3 class="timeline-title">Dropout Regularization</h3>
                    <p class="timeline-description">
                        Hinton et al. introduce dropout, randomly deactivating neurons during training 
                        to prevent overfitting. Becomes standard technique in deep learning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2012</span>
                    <h3 class="timeline-title">Amazon Acquires Kiva Systems</h3>
                    <p class="timeline-description">
                        $775 million acquisition transforms warehouse automation. 
                        Now over 750,000 robots operate in Amazon facilities, revolutionizing logistics.
                    </p>
                    <div class="timeline-tech">Impact: AI-powered supply chain transformation</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">Berkeley's Caffe Framework</h3>
                    <p class="timeline-description">
                        Yangqing Jia releases Caffe at Berkeley, becoming the go-to framework for computer vision research. 
                        Its model zoo concept accelerates research by enabling easy sharing of pre-trained models.
                    </p>
                    <div class="timeline-tech">Impact: Democratized deep learning for vision</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">Word2Vec Released</h3>
                    <p class="timeline-description">
                        Mikolov's team at Google releases Word2Vec, creating efficient word embeddings 
                        that revolutionize NLP by capturing semantic relationships in vector space.
                    </p>
                    <div class="timeline-tech">Innovation: "King - Man + Woman = Queen"</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">ICLR Conference Founded</h3>
                    <p class="timeline-description">
                        International Conference on Learning Representations founded by Yoshua Bengio and Yann LeCun. 
                        Becomes key venue for deep learning research with fully open review process.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">Facebook AI Research (FAIR) Founded</h3>
                    <p class="timeline-description">
                        Yann LeCun joins Facebook to lead FAIR, focusing on open research. 
                        Would later develop PyTorch, now rivaling TensorFlow as preferred framework.
                    </p>
                    <div class="timeline-tech">Philosophy: Open science approach to AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">Generative Adversarial Networks (GANs)</h3>
                    <p class="timeline-description">
                        Ian Goodfellow introduces GANs: two networks competing against each other. 
                        Generator creates fake data, discriminator detects fakes. Revolutionizes generative modeling 
                        and enables unsupervised learning from raw data.
                    </p>
                    <div class="timeline-tech">Impact: Photorealistic image generation, style transfer</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">GloVe Word Embeddings</h3>
                    <p class="timeline-description">
                        Stanford researchers release Global Vectors (GloVe), competing with Word2Vec 
                        by combining global matrix factorization with local context windows.
                    </p>
                    <div class="timeline-tech">Innovation: Unified count-based and predictive methods</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">VGGNet</h3>
                    <p class="timeline-description">
                        Shows that deeper networks with small 3×3 filters outperform shallow networks 
                        with larger filters. Pushes networks to 16-19 layers.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">GoogLeNet/Inception</h3>
                    <p class="timeline-description">
                        Introduces inception modules with multi-scale processing and 1×1 convolutions 
                        for dimensionality reduction. Wins ImageNet with 22 layers.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">Sequence-to-Sequence Models</h3>
                    <p class="timeline-description">
                        Sutskever, Vinyals, and Le introduce seq2seq with encoder-decoder architecture, 
                        revolutionizing machine translation and dialogue systems.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">Gated Recurrent Units (GRU)</h3>
                    <p class="timeline-description">
                        Cho et al. simplify LSTM design while maintaining performance, 
                        making recurrent networks more efficient.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">IBM TrueNorth Neuromorphic Chip</h3>
                    <p class="timeline-description">
                        IBM unveils TrueNorth with 1 million neurons consuming only 70mW, 
                        exploring brain-inspired computing architectures for extreme energy efficiency.
                    </p>
                    <div class="timeline-tech">Innovation: 5.4 billion transistors, event-driven processing</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">Google Photos Incident</h3>
                    <p class="timeline-description">
                        Google Photos' automatic tagging misclassifies Black people in deeply offensive way. 
                        Sparks industry-wide focus on bias detection and responsible AI development, 
                        leading to major changes in how tech companies approach fairness in AI.
                    </p>
                    <div class="timeline-tech">Impact: Watershed moment for AI ethics awareness</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">ResNet - Skip Connections</h3>
                    <p class="timeline-description">
                        He et al. introduce residual connections, enabling training of 100+ layer networks. 
                        Solves degradation problem where deeper networks performed worse. 
                        Wins ImageNet with 152 layers.
                    </p>
                    <div class="timeline-tech">Key insight: Learn residual functions instead of direct mappings</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">Batch Normalization</h3>
                    <p class="timeline-description">
                        Ioffe and Szegedy introduce batch normalization, stabilizing training 
                        and enabling much higher learning rates. Becomes essential for deep networks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">U-Net</h3>
                    <p class="timeline-description">
                        Ronneberger et al. create U-Net for biomedical image segmentation 
                        with encoder-decoder architecture and skip connections.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">YOLO - Real-Time Object Detection</h3>
                    <p class="timeline-description">
                        Joseph Redmon introduces "You Only Look Once," achieving real-time object detection 
                        with a single neural network pass. Revolutionizes computer vision applications.
                    </p>
                    <div class="timeline-tech">Speed: 45 FPS on GPU, enabling real-time applications</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">Keras Deep Learning Library</h3>
                    <p class="timeline-description">
                        François Chollet releases Keras, providing user-friendly API for deep learning. 
                        Later integrated into TensorFlow, democratizing neural network development.
                    </p>
                    <div class="timeline-tech">Philosophy: Deep learning for humans</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">TensorFlow Released</h3>
                    <p class="timeline-description">
                        Google Brain open-sources TensorFlow on November 9, democratizing deep learning development 
                        worldwide. Becomes the most popular deep learning framework with millions of downloads.
                    </p>
                    <div class="timeline-tech">Impact: Accelerated global AI development</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Microsoft Tay Chatbot Incident</h3>
                    <p class="timeline-description">
                        Tay launched March 23, shut down within 24 hours after coordinated attacks exploit learning vulnerabilities. 
                        Chatbot begins posting inflammatory content after learning from malicious users. 
                        Major lesson in AI safety and adversarial attacks.
                    </p>
                    <div class="timeline-tech">Lesson: Unsupervised learning from public data carries risks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">ProPublica COMPAS Investigation</h3>
                    <p class="timeline-description">
                        Exposes algorithmic bias in criminal justice risk assessment, showing black defendants 
                        falsely labeled high-risk at nearly twice the rate of white defendants. 
                        Sparks debate on AI fairness.
                    </p>
                    <div class="timeline-tech">Impact: AI ethics enters public policy debate</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">DenseNet</h3>
                    <p class="timeline-description">
                        Huang et al. connect every layer to every other layer in feedforward fashion, 
                        improving gradient flow and parameter efficiency.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Intel Acquires Nervana</h3>
                    <p class="timeline-description">
                        Intel acquires deep learning startup Nervana for $400 million, signaling major chipmakers' 
                        strategic pivot to AI-specific hardware. Leads to development of Neural Network Processor chips.
                    </p>
                    <div class="timeline-tech">Impact: Traditional silicon giants enter AI chip race</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Google's TPU Announced</h3>
                    <p class="timeline-description">
                        Google reveals custom Tensor Processing Units, deployed internally since 2015. 
                        Strategic shift to custom silicon enables breakthroughs like AlphaGo.
                    </p>
                    <div class="timeline-tech">Performance: 15-30x faster than GPUs for inference</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">AlphaGo Defeats Lee Sedol</h3>
                    <p class="timeline-description">
                        DeepMind's AlphaGo defeats world champion Go player 4-1, 
                        achieving what many thought impossible for decades using deep reinforcement learning.
                    </p>
                    <div class="timeline-tech">Method: Monte Carlo tree search + deep neural networks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">PyTorch Released</h3>
                    <p class="timeline-description">
                        Facebook AI Research releases PyTorch with dynamic computation graphs, 
                        quickly becoming researchers' preferred framework for its flexibility and Pythonic design.
                    </p>
                    <div class="timeline-tech">Innovation: Define-by-run approach</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Federated Learning Introduced</h3>
                    <p class="timeline-description">
                        Google introduces federated learning for training models on decentralized data 
                        without sharing raw information, pioneering privacy-preserving AI.
                    </p>
                    <div class="timeline-tech">Application: On-device learning for mobile keyboards</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Apple Neural Engine</h3>
                    <p class="timeline-description">
                        Apple introduces its Neural Engine in the A11 Bionic chip for iPhone X, bringing dedicated 
                        AI processing to consumer devices. Performs 600 billion operations per second, 
                        enabling Face ID and on-device machine learning.
                    </p>
                    <div class="timeline-tech">Impact: AI acceleration becomes standard in smartphones</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Google Colab Launches</h3>
                    <p class="timeline-description">
                        Google releases Colaboratory, providing free GPU access through Jupyter notebooks in the cloud. 
                        Democratizes deep learning by removing hardware barriers for students and researchers worldwide.
                    </p>
                    <div class="timeline-tech">Impact: Enabled millions to experiment with deep learning</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Transformer Architecture - "Attention Is All You Need"</h3>
                    <p class="timeline-description">
                        Vaswani et al. from Google introduce Transformers, replacing recurrence with self-attention. 
                        Enables parallelization and handling of much longer sequences. 
                        Becomes foundation for all modern language models.
                    </p>
                    <div class="timeline-tech">Impact: GPT, BERT, and entire LLM revolution</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">China's National AI Strategy</h3>
                    <p class="timeline-description">
                        China announces "New Generation AI Development Plan" on July 20, aiming for AI core industry of 1 trillion yuan by 2030. 
                        Triggers global AI competition and massive state investment.
                    </p>
                    <div class="timeline-tech">Impact: Changed global AI dynamics</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">First RLHF Paper</h3>
                    <p class="timeline-description">
                        Christiano et al. publish "Deep Reinforcement Learning from Human Preferences," 
                        introducing the technique that would later make ChatGPT possible.
                    </p>
                    <div class="timeline-tech">Innovation: Learning from human feedback at scale</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Capsule Networks</h3>
                    <p class="timeline-description">
                        Geoffrey Hinton introduces CapsNets with dynamic routing 
                        to better model hierarchical relationships in data.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Intel Loihi Neuromorphic Chip</h3>
                    <p class="timeline-description">
                        Intel announces Loihi, a neuromorphic research chip with 130,000 neurons 
                        and 130 million synapses, advancing brain-inspired computing.
                    </p>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Era of Large Models -->
    <div class="era-separator">
        <h2 class="era-title">The Era of Large Language Models</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Gender Shades Study</h3>
                    <p class="timeline-description">
                        Timnit Gebru and Joy Buolamwini expose systematic bias in commercial facial recognition, 
                        showing error rates up to 34% higher for dark-skinned women. Leads to industry-wide changes.
                    </p>
                    <div class="timeline-tech">Impact: AI ethics becomes mainstream concern</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Cambridge Analytica Scandal</h3>
                    <p class="timeline-description">
                        Facebook data of millions used for political profiling and targeted manipulation. 
                        Exposes dangers of AI-powered behavioral targeting and sparks global privacy regulations.
                    </p>
                    <div class="timeline-tech">Impact: GDPR enforcement, tech regulation momentum</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Lottery Ticket Hypothesis</h3>
                    <p class="timeline-description">
                        Jonathan Frankle and Michael Carbin discover that neural networks contain sparse subnetworks 
                        ("winning lottery tickets") that can achieve comparable accuracy when trained in isolation. 
                        Revolutionizes understanding of network pruning and efficiency.
                    </p>
                    <div class="timeline-tech">Impact: Enables extreme model compression</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Neural Tangent Kernel Theory</h3>
                    <p class="timeline-description">
                        Jacot, Gabriel, and Hongler introduce NTK theory, showing that infinitely wide neural networks 
                        behave like kernel methods during training. Provides new theoretical understanding of deep learning.
                    </p>
                    <div class="timeline-tech">Significance: Bridges deep learning and kernel methods</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">GPT-1</h3>
                    <p class="timeline-description">
                        OpenAI demonstrates unsupervised pre-training with 117M parameters. 
                        Shows that language models can be fine-tuned for various tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">BERT</h3>
                    <p class="timeline-description">
                        Google introduces bidirectional pre-training, achieving state-of-the-art 
                        on 11 NLP tasks. Shows the power of masked language modeling.
                    </p>
                    <div class="timeline-tech">Innovation: Bidirectional context understanding</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Been Kim's TCAV</h3>
                    <p class="timeline-description">
                        Develops Testing with Concept Activation Vectors at Google Brain, 
                        making neural networks more interpretable by understanding what concepts they learn.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2019</span>
                    <h3 class="timeline-title">GPT-2</h3>
                    <p class="timeline-description">
                        OpenAI scales to 1.5B parameters. Initially withheld due to misuse concerns, 
                        sparking debate about AI safety and open research.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2019</span>
                    <h3 class="timeline-title">Pinecone Founded - Vector Database Revolution</h3>
                    <p class="timeline-description">
                        Edo Liberty founds Pinecone, creating specialized infrastructure for vector similarity search. 
                        Public beta launches January 2021, enabling RAG applications that power modern AI.
                    </p>
                    <div class="timeline-tech">Impact: Essential infrastructure for ChatGPT-like systems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2019</span>
                    <h3 class="timeline-title">Spot Robot Goes Commercial</h3>
                    <p class="timeline-description">
                        Boston Dynamics releases Spot for commercial use after 14 years of development, 
                        marking practical deployment of advanced legged robotics.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">Scaling Laws Paper</h3>
                    <p class="timeline-description">
                        Kaplan et al. from OpenAI discover power law relationships between model size, dataset size, 
                        and compute budget. Shows predictable improvements with scale, guiding future model development.
                    </p>
                    <div class="timeline-tech">Impact: Established roadmap for LLM scaling</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">GPT-3</h3>
                    <p class="timeline-description">
                        175B parameters demonstrate emergent few-shot learning abilities. 
                        Can perform tasks with just examples, no fine-tuning needed. 
                        Marks shift to foundation models.
                    </p>
                    <div class="timeline-tech">Breakthrough: In-context learning emerges</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">Vision Transformer (ViT)</h3>
                    <p class="timeline-description">
                        Dosovitskiy et al. apply transformers directly to image patches, 
                        showing convolutions aren't necessary for vision tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">AlphaFold 2 Solves Protein Folding</h3>
                    <p class="timeline-description">
                        DeepMind's AlphaFold achieves atomic-level accuracy in protein structure prediction, 
                        solving a 50-year-old grand challenge in biology. Wins 2024 Nobel Prize in Chemistry.
                    </p>
                    <div class="timeline-tech">Impact: Revolutionizes drug discovery and biology</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">Timnit Gebru Fired from Google</h3>
                    <p class="timeline-description">
                        Google fires AI ethics researcher on December 2 over "Stochastic Parrots" paper critiquing large language models. 
                        2,700+ employees protest. Raises questions about corporate control over AI ethics research.
                    </p>
                    <div class="timeline-tech">Impact: Major turning point in AI ethics debate</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">"Stochastic Parrots" Paper Published</h3>
                    <p class="timeline-description">
                        Bender, Gebru, McMillan-Major, and Mitchell publish landmark critique of LLMs, 
                        warning about environmental costs, bias amplification, and illusions of understanding.
                    </p>
                    <div class="timeline-tech">Legacy: Term becomes standard LLM critique</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">CLIP</h3>
                    <p class="timeline-description">
                        OpenAI aligns vision and language representations through contrastive learning 
                        on 400M image-text pairs. Enables zero-shot image classification.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">DALL-E</h3>
                    <p class="timeline-description">
                        OpenAI demonstrates text-to-image generation using discrete VAE and autoregressive transformer. 
                        Shows AI can create novel visual concepts.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">Liquid Neural Networks</h3>
                    <p class="timeline-description">
                        MIT researchers introduce networks inspired by C. elegans neurons that can adapt 
                        their behavior after training, potentially solving catastrophic forgetting.
                    </p>
                    <div class="timeline-tech">Innovation: Time-continuous, adaptive networks</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">GitHub Copilot Launches</h3>
                    <p class="timeline-description">
                        Technical preview released June 29 based on OpenAI Codex. First widely-adopted AI coding assistant, 
                        transforming software development. General availability June 2022, now used by millions.
                    </p>
                    <div class="timeline-tech">Controversy: Copyright concerns over training on public code</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">Anthropic Founded</h3>
                    <p class="timeline-description">
                        Former OpenAI researchers led by Dario and Daniela Amodei found Anthropic, 
                        focusing on AI safety and building "helpful, harmless, and honest" AI systems.
                    </p>
                    <div class="timeline-tech">Mission: Steerable, interpretable, and safe AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">UNESCO AI Ethics Framework</h3>
                    <p class="timeline-description">
                        193 countries adopt first global agreement on AI ethics, 
                        establishing principles for responsible AI development worldwide.
                    </p>
                    <div class="timeline-tech">Scope: Human rights, transparency, accountability</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">Chain-of-Thought Prompting Discovered</h3>
                    <p class="timeline-description">
                        Jason Wei et al. at Google publish breakthrough showing that providing reasoning steps dramatically improves 
                        large model performance. GSM8K math accuracy jumps from 17.9% to 56.9%.
                    </p>
                    <div class="timeline-tech">Impact: Revolutionized how we interact with LLMs</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">InstructGPT and RLHF</h3>
                    <p class="timeline-description">
                        OpenAI shows that 1.3B parameter InstructGPT is preferred over 175B GPT-3 thanks to RLHF. 
                        Demonstrates that alignment matters more than scale.
                    </p>
                    <div class="timeline-tech">Breakthrough: Human feedback improves AI behavior</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">Chinchilla Scaling Laws</h3>
                    <p class="timeline-description">
                        DeepMind publishes "compute-optimal" training showing models need ~20 tokens per parameter. 
                        70B Chinchilla outperforms much larger models, revolutionizing training efficiency.
                    </p>
                    <div class="timeline-tech">Impact: Changed how all LLMs are trained</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">Flash Attention</h3>
                    <p class="timeline-description">
                        Dao et al. introduce IO-aware exact attention algorithm, reducing memory usage 
                        from quadratic to linear and enabling much longer context windows efficiently.
                    </p>
                    <div class="timeline-tech">Impact: Enabled 100K+ token context windows</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">Midjourney Beta Launch</h3>
                    <p class="timeline-description">
                        David Holz releases Midjourney, becoming cultural phenomenon with artistic, 
                        dreamlike image generation. Operates entirely through Discord, reaching millions.
                    </p>
                    <div class="timeline-tech">Impact: Made AI art mainstream and accessible</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">Stable Diffusion</h3>
                    <p class="timeline-description">
                        Stability AI releases open-source text-to-image diffusion model. 
                        Democratizes AI art generation, sparking creative revolution and controversy.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">OpenAI Whisper Released</h3>
                    <p class="timeline-description">
                        Open-source speech recognition trained on 680,000 hours of multilingual audio. 
                        Supports 99 languages with near-human accuracy, democratizing speech AI.
                    </p>
                    <div class="timeline-tech">Models: Six sizes from 39M to 1.5B parameters</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">Instant Neural Graphics Primitives</h3>
                    <p class="timeline-description">
                        NVIDIA introduces Instant NGP, achieving real-time neural radiance field (NeRF) rendering. 
                        Reduces training time from hours to seconds using multi-resolution hash encoding, 
                        enabling instant 3D scene reconstruction from 2D images.
                    </p>
                    <div class="timeline-tech">Breakthrough: Real-time neural 3D rendering</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">LangChain Framework</h3>
                    <p class="timeline-description">
                        Harrison Chase releases LangChain, enabling complex LLM applications with 
                        chains, agents, and tools. Accelerates development of AI-powered applications.
                    </p>
                    <div class="timeline-tech">Impact: Simplified building LLM applications</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">ChatGPT Launch</h3>
                    <p class="timeline-description">
                        OpenAI releases ChatGPT on November 30, reaching 100M users in 2 months - fastest in history. 
                        Brings conversational AI to mainstream, triggering global AI awareness and investment boom.
                    </p>
                    <div class="timeline-tech">Impact: AI becomes household technology</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">AlphaFold Database Release</h3>
                    <p class="timeline-description">
                        DeepMind releases structures for 200 million proteins - nearly all known to science. 
                        Makes decades of potential research freely available overnight.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">ElevenLabs Voice Cloning</h3>
                    <p class="timeline-description">
                        Founded by Piotr Dąbkowski and Mati Staniszewski, beta launches January 2023. 
                        Achieves realistic voice cloning from just 5-30 seconds of audio, revolutionizing voice synthesis.
                    </p>
                    <div class="timeline-tech">Valuation: $3.3B by 2025, raises ethics concerns</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Auto-GPT Launches Autonomous AI Era</h3>
                    <p class="timeline-description">
                        Toran Bruce Richards releases Auto-GPT on March 30, gaining 177,000+ GitHub stars. 
                        First autonomous AI agent that can break down tasks and execute them independently. 
                        AgentGPT follows in April.
                    </p>
                    <div class="timeline-tech">Significance: Early AGI experiments highlight potential and limitations</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Constitutional AI</h3>
                    <p class="timeline-description">
                        Anthropic develops training method using AI feedback based on constitutional principles 
                        rather than extensive human feedback. Enables more precise control.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Meta's Segment Anything Model</h3>
                    <p class="timeline-description">
                        Released April 5 with SA-1B dataset containing 1.1 billion masks. 
                        Enables zero-shot segmentation with flexible prompting (clicks, boxes, text). 
                        Establishes computer vision foundation models.
                    </p>
                    <div class="timeline-tech">Team Lead: Alexander Kirillov at Meta AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">LlamaIndex (GPT Index) Matures</h3>
                    <p class="timeline-description">
                        Jerry Liu's LlamaIndex becomes essential for connecting LLMs to private data, 
                        complementing LangChain with focus on data ingestion and retrieval.
                    </p>
                    <div class="timeline-tech">Innovation: Advanced RAG techniques</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">LIDA - Automated Data Visualization</h3>
                    <p class="timeline-description">
                        Microsoft Research releases LIDA (Language-based Interactive Data Analysis), 
                        combining LLMs with visualization generation. Automatically creates meaningful 
                        charts and insights from natural language queries about data.
                    </p>
                    <div class="timeline-tech">Innovation: LLM-powered automated analytics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Claude 1 Launch</h3>
                    <p class="timeline-description">
                        Anthropic releases Claude with 9,000 token context and strong conversational abilities. 
                        Emphasizes safety and helpfulness through Constitutional AI training.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">GPT-4</h3>
                    <p class="timeline-description">
                        OpenAI's multimodal model with estimated 500B-1.7T parameters. 
                        Shows significant improvements in reasoning and reduced hallucination.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Mixtral 8x7B</h3>
                    <p class="timeline-description">
                        Mistral AI releases open-source Mixture of Experts model, achieving GPT-3.5 
                        performance with efficient sparse activation. Democratizes advanced architectures.
                    </p>
                    <div class="timeline-tech">Innovation: Open MoE models become viable</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Video Generation Explosion</h3>
                    <p class="timeline-description">
                        Runway Gen-2, Pika Labs, and Stability AI's SVD democratize video generation. 
                        Text-to-video becomes accessible to creators, transforming content production.
                    </p>
                    <div class="timeline-tech">Impact: AI enters video production mainstream</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Open Source Explosion</h3>
                    <p class="timeline-description">
                        Meta's LLaMA leak sparks open-source revolution. 
                        Mistral, Falcon, MPT, Microsoft Phi, Google Gemma, Cohere Command R, 
                        and dozens of models democratize LLM access.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">FDA Approves 700+ AI Medical Devices</h3>
                    <p class="timeline-description">
                        Over 700 AI algorithms approved for medical use, with 76% in radiology. 
                        AI becomes standard in medical imaging and diagnostics.
                    </p>
                    <div class="timeline-tech">Applications: Cancer detection, cardiac analysis, stroke diagnosis</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2023</span>
                    <h3 class="timeline-title">Google NotebookLM</h3>
                    <p class="timeline-description">
                        Steven Johnson leads development of AI research assistant that can analyze documents 
                        and generate podcast-style audio discussions, pioneering multimodal knowledge synthesis.
                    </p>
                    <div class="timeline-tech">Innovation: AI-generated educational podcasts</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">Sora by OpenAI</h3>
                    <p class="timeline-description">
                        OpenAI unveils Sora, generating cinema-quality minute-long videos from text. 
                        Demonstrates understanding of physics, persistence, and complex scene dynamics.
                    </p>
                    <div class="timeline-tech">Breakthrough: Photorealistic video with coherent physics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">Claude 3 Family</h3>
                    <p class="timeline-description">
                        Anthropic releases Opus, Sonnet, and Haiku models with multimodal capabilities 
                        and 200,000 token context windows.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">India's AI Mission Launches</h3>
                    <p class="timeline-description">
                        IndiaAI Mission approved March 7 with Rs 10,370 crore budget. 
                        Jugalbandi supports 50+ Indian languages, demonstrating AI for linguistic diversity.
                    </p>
                    <div class="timeline-tech">Focus: Inclusive AI development</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">Groq LPU - Ultra-Fast Inference</h3>
                    <p class="timeline-description">
                        Groq's Language Processing Units achieve 500+ tokens/second inference speed, 
                        10x faster than GPUs. Demonstrates potential for real-time AI applications.
                    </p>
                    <div class="timeline-tech">Innovation: Specialized AI inference hardware</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">African Union AI Strategy</h3>
                    <p class="timeline-description">
                        Continental AI Strategy endorsed July 2024. Eight African nations have strategies, 
                        with focus on language preservation and local solutions. Mauritius first in 2018.
                    </p>
                    <div class="timeline-tech">Priority: African language AI models</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">EU AI Act Enters Force</h3>
                    <p class="timeline-description">
                        World's first comprehensive AI regulation formally adopted in May, enters force August. 
                        Sets global precedent for AI governance with risk-based approach.
                    </p>
                    <div class="timeline-tech">Impact: Shapes global AI regulation standards</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">Humanoid Robot Renaissance</h3>
                    <p class="timeline-description">
                        Tesla Optimus, Figure 01, 1X Technologies, and others showcase advanced humanoid robots. 
                        Figure raises $675M with OpenAI backing, signaling serious commercialization push.
                    </p>
                    <div class="timeline-tech">Goal: General-purpose robots for human environments</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">Claude Computer Use</h3>
                    <p class="timeline-description">
                        Anthropic introduces AI that can directly control computers, 
                        marking shift from text generation to autonomous action.
                    </p>
                    <div class="timeline-tech">Capability: AI as autonomous agent</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">OpenAI o1 and o3 Models</h3>
                    <p class="timeline-description">
                        OpenAI shifts from pure generation to deliberate reasoning with o-series models, 
                        showing significant improvements in mathematical and logical reasoning.
                    </p>
                    <div class="timeline-tech">Innovation: Chain-of-thought reasoning at scale</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2024</span>
                    <h3 class="timeline-title">DeepSeek Open Models</h3>
                    <p class="timeline-description">
                        Chinese company DeepSeek releases models achieving GPT-4 level performance 
                        at fraction of training cost, challenging assumptions about compute requirements.
                    </p>
                    <div class="timeline-tech">Significance: Democratizes advanced AI globally</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Current State and Future -->
    <div class="era-separator">
        <h2 class="era-title">Current State and Future of AI</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Claude Opus 4</h3>
                    <p class="timeline-description">
                        Current state-of-the-art with 72.5% on SWE-bench. Features hybrid reasoning with 64K thinking tokens, 
                        capable of 7+ hours autonomous coding. Represents culmination of 2,400 years of progress 
                        from Aristotle's logic to modern AI.
                    </p>
                    <div class="timeline-tech">Capabilities: Extended reasoning, multimodal understanding, code generation</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Meta Llama 4</h3>
                    <p class="timeline-description">
                        First open-weight natively multimodal models with mixture-of-experts architecture, 
                        challenging closed-source model dominance and advancing open AI development.
                    </p>
                    <div class="timeline-tech">Innovation: Open multimodal foundation models</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Current Landscape</h3>
                    <p class="timeline-description">
                        Thousands of models from numerous companies: Google's Gemini, Meta's LLaMA 3, 
                        Anthropic's Claude, OpenAI's GPT series, Mistral, DeepSeek, Qwen, and many others. 
                        AI integration becoming ubiquitous in software.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Global AI Innovation</h3>
                    <p class="timeline-description">
                        • China: Baidu ERNIE Bot serves 200M users<br>
                        • Israel: 2,170 AI companies (30% of tech sector)<br>
                        • Canada: Vector Institute and Mila lead research<br>
                        • South Korea: Exaone 3.0 open-source LLM<br>
                        • Europe: Leading AI regulation and ethics<br>
                        • Japan: Society 5.0 integrating AI with robotics<br>
                        • Latin America: Chile's Latam-GPT project
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Technical Innovations</h3>
                    <p class="timeline-description">
                        • Efficient architectures: Mamba, RWKV challenging transformers<br>
                        • Mixture of Experts for scale<br>
                        • Flash Attention for memory efficiency<br>
                        • LoRA/QLoRA for efficient fine-tuning<br>
                        • RAG for knowledge integration<br>
                        • Native multimodality in foundation models
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">AI in Production</h3>
                    <p class="timeline-description">
                        • 750,000+ robots in Amazon warehouses<br>
                        • Robo-advisors managing $4.66 trillion projected by 2027<br>
                        • AI agents handling customer service at scale<br>
                        • Autonomous coding assistants in development teams<br>
                        • AI-powered drug discovery accelerating
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Current Challenges</h3>
                    <p class="timeline-description">
                        • Hallucination and reliability<br>
                        • Computational costs and energy usage<br>
                        • AI safety and alignment<br>
                        • Corporate responsibility<br>
                        • Democratization vs. concentration of power<br>
                        • Global governance and regulation
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Rapid Evolution</h3>
                    <p class="timeline-description">
                        Field changes so rapidly that long-term frameworks become obsolete quickly. 
                        Platforms like GitHub, HuggingFace, and Leanpub enable real-time knowledge sharing. 
                        Open-source community driving innovation alongside big tech.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date future">Future</span>
                    <h3 class="timeline-title">The Road Ahead</h3>
                    <p class="timeline-description">
                        From Aristotle's binary logic to Claude Opus 4's extended reasoning, 
                        AI represents humanity's longest intellectual project. The journey continues with:<br><br>
                        • AGI aspirations (Shane Legg: 50% chance by 2028)<br>
                        • Multimodal reasoning<br>
                        • Embodied AI and robotics<br>
                        • Quantum-AI integration<br>
                        • Ensuring beneficial outcomes for humanity
                    </p>
                    <div class="timeline-tech">Key: Balancing capability with safety and accessibility</div>
                </div>
            </div>
            
<div class="timeline-item">
    <div class="timeline-dot"></div>
    <div class="timeline-content">
        <span class="timeline-date reflection">Reflection</span>
        <h3 class="timeline-title">2,400 Years of Progress</h3>
        <p class="timeline-description">
            What began with philosophers asking "What is thought?" has evolved into systems 
            that can write, create, reason, and assist. Each breakthrough built on centuries 
            of accumulated knowledge, showing AI as not a sudden invention but humanity's 
            longest quest to understand and recreate intelligence.
        </p>
    </div>
</div>

<!-- NOW add the You Were Here entry as a separate item -->
<div class="timeline-item">
    <div class="timeline-dot" style="background: linear-gradient(135deg, #FF5722, #2196F3); width: 20px; height: 20px;"></div>
    <div class="timeline-content" style="border: 2px solid transparent; background-image: linear-gradient(#141414, #141414), linear-gradient(135deg, #FF5722, #2196F3); background-origin: border-box; background-clip: content-box, border-box;">
        <span class="timeline-date" style="background: linear-gradient(135deg, #FF5722, #2196F3); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; border: none;">Right Now</span>
        <h3 class="timeline-title">You Were Here</h3>
        <p class="timeline-description">
            Reader finishes browsing this timeline, brain slightly dizzy from the scope of human ambition. 
            Returns to main text with newfound appreciation for how a thought experiment in ancient Greece 
            somehow led to an AI that can help write books about itself. 
            The loop closes. The story continues.
        </p>
        <div class="timeline-tech" style="color: #FF5722;">Status: Enlightened and ready for the next appendix ✨</div>
    </div>
</div>
