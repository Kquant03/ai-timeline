<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI History Timeline - Journey Through Intelligence</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #0a0a0a;
            color: #ffffff;
            overflow-x: hidden;
            position: relative;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        
        /* Subtle animated background gradient */
        .background-gradient {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: 
                radial-gradient(circle at 20% 50%, rgba(33, 150, 243, 0.08) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(255, 87, 34, 0.05) 0%, transparent 50%),
                radial-gradient(circle at 50% 50%, rgba(100, 181, 246, 0.03) 0%, transparent 70%),
                #0a0a0a;
            z-index: -2;
            animation: gradientShift 20s ease-in-out infinite;
        }
        
        @keyframes gradientShift {
            0%, 100% {
                transform: scale(1) rotate(0deg);
            }
            50% {
                transform: scale(1.1) rotate(1deg);
            }
        }
        
        /* Subtle floating orbs instead of particles */
        .orbs {
            position: fixed;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: -1;
        }
        
        .orb {
            position: absolute;
            border-radius: 50%;
            filter: blur(40px);
            opacity: 0;
            animation: floatOrb 30s infinite;
        }
        
        .orb:nth-child(1) {
            width: 300px;
            height: 300px;
            background: radial-gradient(circle, rgba(33, 150, 243, 0.3) 0%, transparent 70%);
            left: -150px;
            animation-delay: 0s;
        }
        
        .orb:nth-child(2) {
            width: 200px;
            height: 200px;
            background: radial-gradient(circle, rgba(255, 87, 34, 0.2) 0%, transparent 70%);
            right: -100px;
            animation-delay: 10s;
        }
        
        .orb:nth-child(3) {
            width: 250px;
            height: 250px;
            background: radial-gradient(circle, rgba(100, 181, 246, 0.25) 0%, transparent 70%);
            left: 50%;
            animation-delay: 20s;
        }
        
        @keyframes floatOrb {
            0% {
                transform: translateY(100vh) translateX(0) scale(0.8);
                opacity: 0;
            }
            10% {
                opacity: 0.4;
            }
            90% {
                opacity: 0.4;
            }
            100% {
                transform: translateY(-100vh) translateX(100px) scale(1.2);
                opacity: 0;
            }
        }
        
        /* Hero section with legend */
        .hero {
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            position: relative;
            z-index: 2;
            padding: 40px 20px;
        }
        
        .hero h1 {
            font-size: clamp(3rem, 8vw, 5.5rem);
            font-weight: 700;
            text-align: center;
            background: linear-gradient(135deg, #2196F3 0%, #64B5F6 25%, #42A5F5 50%, #FF5722 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 20px;
            animation: titleGlow 4s ease-in-out infinite;
            background-size: 200% 200%;
        }
        
        @keyframes titleGlow {
            0%, 100% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
        }
        
        .hero-subtitle {
            font-size: clamp(1rem, 3vw, 1.5rem);
            color: #64B5F6;
            opacity: 0;
            text-align: center;
            margin-bottom: 10px;
            animation: fadeInUp 1s ease forwards;
        }
        
        .hero-subtitle:nth-child(2) {
            animation-delay: 0.3s;
        }
        
        .hero-subtitle:nth-child(3) {
            animation-delay: 0.6s;
        }
        
        @keyframes fadeInUp {
            to {
                opacity: 0.9;
                transform: translateY(0);
            }
            from {
                opacity: 0;
                transform: translateY(20px);
            }
        }
        
        /* Legend */
        .legend {
            margin-top: 60px;
            padding: 25px 35px;
            background: rgba(20, 20, 20, 0.6);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            display: flex;
            gap: 40px;
            align-items: center;
            opacity: 0;
            animation: fadeInUp 1s ease 0.9s forwards;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 12px;
        }
        
        .legend-dot {
            width: 24px;
            height: 24px;
            border-radius: 50%;
            border: 3px solid #0a0a0a;
            box-shadow: 0 0 10px rgba(33, 150, 243, 0.3);
            position: relative;
        }
        
        .legend-dot::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: inherit;
            filter: blur(10px);
            opacity: 0.5;
            z-index: -1;
        }
        
        .legend-dot.regular {
            background: #2196F3;
        }
        
        .legend-dot.major {
            background: #FF5722;
            width: 28px;
            height: 28px;
        }
        
        .legend-dot.future {
            background: #8B5CF6;
        }
        
        .legend-dot.reflection {
            background: #10B981;
        }
        
        .legend-label {
            font-size: 14px;
            color: rgba(255, 255, 255, 0.8);
            font-weight: 500;
        }
        
        .scroll-indicator {
            position: absolute;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            opacity: 0;
            animation: fadeIn 1s ease 1.2s forwards, float 3s ease-in-out infinite 1.2s;
            cursor: pointer;
        }
        
        @keyframes fadeIn {
            to {
                opacity: 0.7;
            }
        }
        
        @keyframes float {
            0%, 100% {
                transform: translateX(-50%) translateY(0);
            }
            50% {
                transform: translateX(-50%) translateY(10px);
            }
        }
        
        .scroll-indicator:hover {
            opacity: 1 !important;
        }
        
        /* Timeline sections */
        .timeline-section {
            position: relative;
            padding: 80px 0;
            z-index: 10;
        }
        
        .timeline-container {
            max-width: 1200px;
            margin: 0 auto;
            position: relative;
            padding: 0 40px;
        }
        
        /* Timeline line with glow */
        .timeline-line {
            position: absolute;
            left: 50%;
            top: 0;
            bottom: 0;
            width: 2px;
            background: linear-gradient(to bottom, 
                transparent 0%, 
                #2196F3 10%, 
                #2196F3 90%, 
                transparent 100%
            );
            transform: translateX(-50%);
        }
        
        .timeline-line::after {
            content: '';
            position: absolute;
            top: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 20px;
            height: 100%;
            background: linear-gradient(to bottom,
                transparent 0%,
                rgba(33, 150, 243, 0.2) 10%,
                rgba(33, 150, 243, 0.2) 90%,
                transparent 100%
            );
            filter: blur(10px);
            pointer-events: none;
        }
        
        /* Timeline items with refined animations */
        .timeline-item {
            position: relative;
            margin-bottom: 80px;
            opacity: 0;
            transform: translateY(20px);
            transition: all 0.8s cubic-bezier(0.4, 0, 0.2, 1);
        }
        
        .timeline-item.visible {
            opacity: 1;
            transform: translateY(0);
        }
        
        .timeline-item:nth-child(even) {
            text-align: right;
            padding-right: 52%;
        }
        
        .timeline-item:nth-child(odd) {
            text-align: left;
            padding-left: 52%;
        }
        
        /* Timeline dots with subtle glow animation */
        .timeline-dot {
            position: absolute;
            width: 24px;
            height: 24px;
            background: #2196F3;
            border: 3px solid #0a0a0a;
            border-radius: 50%;
            top: 5px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 2;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            box-shadow: 0 0 20px rgba(33, 150, 243, 0.4);
        }
        
        .timeline-dot::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: inherit;
            animation: pulse 2s ease-in-out infinite;
            z-index: -1;
        }
        
        @keyframes pulse {
            0%, 100% {
                transform: translate(-50%, -50%) scale(1);
                opacity: 0.5;
            }
            50% {
                transform: translate(-50%, -50%) scale(1.5);
                opacity: 0;
            }
        }
        
        .timeline-item:hover .timeline-dot {
            transform: translateX(-50%) scale(1.2);
            box-shadow: 0 0 30px rgba(33, 150, 243, 0.6);
        }
        
        .timeline-dot.major {
            width: 32px;
            height: 32px;
            background: #FF5722;
            box-shadow: 0 0 20px rgba(255, 87, 34, 0.4);
        }
        
        /* Content cards with refined hover */
        .timeline-content {
            background: rgba(20, 20, 20, 0.8);
            backdrop-filter: blur(10px);
            padding: 28px;
            border-radius: 16px;
            border: 1px solid rgba(255, 255, 255, 0.08);
            position: relative;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            overflow: hidden;
        }
        
        .timeline-content::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 1px;
            background: linear-gradient(90deg, transparent, rgba(33, 150, 243, 0.5), transparent);
            transform: translateX(-100%);
            transition: transform 0.6s ease;
        }
        
        .timeline-content:hover::before {
            transform: translateX(100%);
        }
        
        .timeline-content:hover {
            transform: translateY(-5px);
            box-shadow: 
                0 20px 40px rgba(0, 0, 0, 0.3),
                0 0 60px rgba(33, 150, 243, 0.05);
            border-color: rgba(33, 150, 243, 0.2);
        }
        
        /* Date badges with glow */
        .timeline-date {
            display: inline-block;
            background: rgba(26, 26, 26, 0.9);
            color: #64B5F6;
            padding: 8px 18px;
            border-radius: 25px;
            font-weight: 600;
            font-size: 13px;
            margin-bottom: 15px;
            border: 1px solid #2196F3;
            letter-spacing: 0.5px;
            box-shadow: 0 0 20px rgba(33, 150, 243, 0.2);
        }
        
        .timeline-date.future {
            border-color: #8B5CF6;
            color: #8B5CF6;
            box-shadow: 0 0 20px rgba(139, 92, 246, 0.2);
        }
        
        .timeline-date.reflection {
            border-color: #10B981;
            color: #10B981;
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.2);
        }
        
        .timeline-title {
            font-size: 24px;
            font-weight: 600;
            margin-bottom: 15px;
            color: #ffffff;
            line-height: 1.3;
        }
        
        .timeline-description {
            color: rgba(255, 255, 255, 0.75);
            line-height: 1.8;
            font-size: 15px;
        }
        
        .timeline-tech {
            margin-top: 15px;
            font-size: 13px;
            color: #64B5F6;
            font-style: italic;
            padding-top: 15px;
            border-top: 1px solid rgba(255, 255, 255, 0.08);
            opacity: 0.9;
        }
        
        /* Era separators with refined design */
        .era-separator {
            position: relative;
            height: 200px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 100px 0;
        }
        
        .era-separator::before {
            content: '';
            position: absolute;
            width: 60%;
            height: 1px;
            background: linear-gradient(90deg, 
                transparent, 
                rgba(33, 150, 243, 0.3), 
                rgba(33, 150, 243, 0.5),
                rgba(33, 150, 243, 0.3),
                transparent
            );
        }
        
        .era-title {
            font-size: clamp(1.5rem, 4vw, 2.5rem);
            font-weight: 600;
            text-align: center;
            padding: 20px 40px;
            background: linear-gradient(135deg, rgba(10, 10, 10, 0.95), rgba(20, 20, 20, 0.95));
            backdrop-filter: blur(10px);
            border: 2px solid transparent;
            background-clip: padding-box;
            border-radius: 50px;
            position: relative;
            z-index: 2;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.5);
        }
        
        .era-title::before {
            content: '';
            position: absolute;
            top: -2px;
            left: -2px;
            right: -2px;
            bottom: -2px;
            background: linear-gradient(135deg, #2196F3, #FF5722);
            border-radius: 50px;
            z-index: -1;
            opacity: 0.7;
        }
        
        /* Footer */
        .footer {
            text-align: center;
            padding: 100px 20px 60px;
            color: #64B5F6;
            font-size: 1.2em;
            position: relative;
            opacity: 0.8;
        }
        
        /* Responsive adjustments */
        @media (max-width: 768px) {
            .legend {
                flex-direction: column;
                gap: 20px;
                padding: 20px 25px;
            }
            
            .timeline-item:nth-child(even),
            .timeline-item:nth-child(odd) {
                padding: 0 20px 0 60px;
                text-align: left;
            }
            
            .timeline-line {
                left: 30px;
            }
            
            .timeline-dot {
                left: 30px;
            }
            
            .timeline-content {
                padding: 20px;
            }
        }
        
        /* Reduced motion preferences */
        @media (prefers-reduced-motion: reduce) {
            * {
                animation: none !important;
                transition: opacity 0.3s ease !important;
            }
        }
    </style>
</head>
<body>
    <!-- Subtle animated background -->
    <div class="background-gradient"></div>
    
    <!-- Floating orbs for ambiance -->
    <div class="orbs">
        <div class="orb"></div>
        <div class="orb"></div>
        <div class="orb"></div>
    </div>
    
    <!-- Hero Section with Legend -->
    <div class="hero">
        <h1>The Evolution of AI</h1>
        <p class="hero-subtitle">From Ancient Logic to Modern Intelligence</p>
        <p class="hero-subtitle">2,400 Years of Human Ingenuity</p>
        
        <!-- Legend -->
        <div class="legend">
            <div class="legend-item">
                <div class="legend-dot regular"></div>
                <span class="legend-label">Key Development</span>
            </div>
            <div class="legend-item">
                <div class="legend-dot major"></div>
                <span class="legend-label">Major Breakthrough</span>
            </div>
            <div class="legend-item">
                <div class="legend-dot future"></div>
                <span class="legend-label">Future Outlook</span>
            </div>
            <div class="legend-item">
                <div class="legend-dot reflection"></div>
                <span class="legend-label">Reflection</span>
            </div>
        </div>
        
        <div class="scroll-indicator">
            <svg width="30" height="30" viewBox="0 0 30 30">
                <path d="M15 8 L15 22 M9 16 L15 22 L21 16" stroke="#64B5F6" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
        </div>
    </div>
    
    <!-- Ancient Foundations Era -->
    <div class="era-separator">
        <h2 class="era-title">Ancient Foundations to Early Computing</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">384 BCE</span>
                    <h3 class="timeline-title">Aristotle's Formal Logic</h3>
                    <p class="timeline-description">
                        "A single assertion must always either affirm or deny a single predicate of a single subject." 
                        Aristotle establishes formal reasoning and syllogistic logic, creating the binary foundation that would eventually underpin all digital computing.
                    </p>
                    <div class="timeline-tech">Contribution: Binary logic, formal reasoning systems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">279 BCE</span>
                    <h3 class="timeline-title">Stoic Propositional Logic</h3>
                    <p class="timeline-description">
                        Chrysippus of Soli develops propositional logic focusing on relationships between complete statements. 
                        Introduces conditional reasoning ("if-then" structures) remarkably similar to modern Boolean logic.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">820 CE</span>
                    <h3 class="timeline-title">Al-Khwarizmi's Algorithms</h3>
                    <p class="timeline-description">
                        Muhammad ibn Musa al-Khwarizmi introduces systematic, step-by-step problem-solving procedures. 
                        The word "algorithm" derives from his name, establishing the conceptual framework for all computational processes.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1275</span>
                    <h3 class="timeline-title">Ramon Llull's Ars Magna</h3>
                    <p class="timeline-description">
                        Creates the first mechanical reasoning device using rotating paper disks to generate logical combinations. 
                        Considered the first attempt at mechanizing thought processes.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1642</span>
                    <h3 class="timeline-title">Pascal's Calculator</h3>
                    <p class="timeline-description">
                        Blaise Pascal builds the first mechanical calculator, demonstrating that machines could perform mathematical reasoning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1679</span>
                    <h3 class="timeline-title">Leibniz's Binary System</h3>
                    <p class="timeline-description">
                        Gottfried Wilhelm Leibniz develops the modern binary number system (0 and 1), 
                        inspired by the I Ching. This mathematical representation becomes the foundation 
                        for all digital computers.
                    </p>
                    <div class="timeline-tech">Impact: Enabled digital representation of information</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1804</span>
                    <h3 class="timeline-title">Jacquard Loom</h3>
                    <p class="timeline-description">
                        Joseph Marie Jacquard invents a loom controlled by punched cards, creating complex patterns automatically. 
                        First practical programmable machine, directly inspiring Babbage's Analytical Engine.
                    </p>
                    <div class="timeline-tech">Innovation: Stored programs via punched cards</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1837</span>
                    <h3 class="timeline-title">Babbage's Analytical Engine</h3>
                    <p class="timeline-description">
                        Charles Babbage designs the first Turing-complete mechanical computer. 
                        Ada Lovelace writes the first algorithm and envisions computers beyond mere calculation.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1854</span>
                    <h3 class="timeline-title">Boolean Algebra</h3>
                    <p class="timeline-description">
                        George Boole publishes "An Investigation of the Laws of Thought," introducing Boolean algebra with AND, OR, NOT operations. 
                        This mathematical formalization of logic would later be recognized as the foundation of digital circuit design.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of all modern computing</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1879</span>
                    <h3 class="timeline-title">Frege's Predicate Logic</h3>
                    <p class="timeline-description">
                        Gottlob Frege creates the first complete system of predicate logic in his Begriffsschrift, 
                        providing the rigorous formal framework necessary for automated reasoning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1880</span>
                    <h3 class="timeline-title">Venn Diagrams</h3>
                    <p class="timeline-description">
                        John Venn introduces Venn diagrams for visualizing set theory relationships, 
                        making logical relationships more intuitive and accessible.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1910-13</span>
                    <h3 class="timeline-title">Principia Mathematica</h3>
                    <p class="timeline-description">
                        Whitehead and Russell attempt to derive all mathematics from logical principles. 
                        This monumental work makes AI seem feasible by suggesting all reasoning could be formalized.
                    </p>
                    <div class="timeline-tech">Significance: Inspired the quest to mechanize thought</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1936</span>
                    <h3 class="timeline-title">Turing Machine</h3>
                    <p class="timeline-description">
                        Alan Turing introduces the theoretical Turing Machine, proving that a simple device manipulating symbols 
                        could perform any computation. Establishes the theoretical foundation of computer science.
                    </p>
                    <div class="timeline-tech">Legacy: Defined the limits of mechanical computation</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Current State and Future -->
    <div class="era-separator">
        <h2 class="era-title">Current State and Future of AI</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Claude Opus 4</h3>
                    <p class="timeline-description">
                        Current state-of-the-art with 72.5% on SWE-bench. Features hybrid reasoning with 64K thinking tokens, 
                        capable of 7+ hours autonomous coding. Represents culmination of 2,400 years of progress 
                        from Aristotle's logic to modern AI.
                    </p>
                    <div class="timeline-tech">Capabilities: Extended reasoning, multimodal understanding, code generation</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Meta Llama 4</h3>
                    <p class="timeline-description">
                        First open-weight natively multimodal models with mixture-of-experts architecture, 
                        challenging closed-source model dominance and advancing open AI development.
                    </p>
                    <div class="timeline-tech">Innovation: Open multimodal foundation models</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Current Landscape</h3>
                    <p class="timeline-description">
                        Thousands of models from numerous companies: Google's Gemini, Meta's LLaMA 3, 
                        Anthropic's Claude, OpenAI's GPT series, Mistral, DeepSeek, Qwen, and many others. 
                        AI integration becoming ubiquitous in software.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Global AI Innovation</h3>
                    <p class="timeline-description">
                        • China: Baidu ERNIE Bot serves 200M users<br>
                        • Israel: 2,170 AI companies (30% of tech sector)<br>
                        • Canada: Vector Institute and Mila lead research<br>
                        • South Korea: Exaone 3.0 open-source LLM<br>
                        • Europe: Leading AI regulation and ethics<br>
                        • Japan: Society 5.0 integrating AI with robotics<br>
                        • Latin America: Chile's Latam-GPT project
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Technical Innovations</h3>
                    <p class="timeline-description">
                        • Efficient architectures: Mamba, RWKV challenging transformers<br>
                        • Mixture of Experts for scale<br>
                        • Flash Attention for memory efficiency<br>
                        • LoRA/QLoRA for efficient fine-tuning<br>
                        • RAG for knowledge integration<br>
                        • Native multimodality in foundation models
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">AI in Production</h3>
                    <p class="timeline-description">
                        • 750,000+ robots in Amazon warehouses<br>
                        • Robo-advisors managing $4.66 trillion projected by 2027<br>
                        • AI agents handling customer service at scale<br>
                        • Autonomous coding assistants in development teams<br>
                        • AI-powered drug discovery accelerating
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Current Challenges</h3>
                    <p class="timeline-description">
                        • Hallucination and reliability<br>
                        • Computational costs and energy usage<br>
                        • AI safety and alignment<br>
                        • Corporate responsibility<br>
                        • Democratization vs. concentration of power<br>
                        • Global governance and regulation
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2025</span>
                    <h3 class="timeline-title">Rapid Evolution</h3>
                    <p class="timeline-description">
                        Field changes so rapidly that long-term frameworks become obsolete quickly. 
                        Platforms like GitHub, HuggingFace, and Leanpub enable real-time knowledge sharing. 
                        Open-source community driving innovation alongside big tech.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date future">Future</span>
                    <h3 class="timeline-title">The Road Ahead</h3>
                    <p class="timeline-description">
                        From Aristotle's binary logic to Claude Opus 4's extended reasoning, 
                        AI represents humanity's longest intellectual project. The journey continues with:<br><br>
                        • AGI aspirations (Shane Legg: 50% chance by 2028)<br>
                        • Multimodal reasoning<br>
                        • Embodied AI and robotics<br>
                        • Quantum-AI integration<br>
                        • Ensuring beneficial outcomes for humanity
                    </p>
                    <div class="timeline-tech">Key: Balancing capability with safety and accessibility</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date reflection">Reflection</span>
                    <h3 class="timeline-title">2,400 Years of Progress</h3>
                    <p class="timeline-description">
                        What began with philosophers asking "What is thought?" has evolved into systems 
                        that can write, create, reason, and assist. Each breakthrough built on centuries 
                        of accumulated knowledge, showing AI as not a sudden invention but humanity's 
                        longest quest to understand and recreate intelligence.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date reflection">Reflection</span>
                    <h3 class="timeline-title">You Were Here</h3>
                    <p class="timeline-description">
                        Reader finishes browsing this timeline, brain slightly dizzy from the scope of human ambition. 
                        Returns to main text with newfound appreciation for how a thought experiment in ancient Greece 
                        somehow led to an AI that can help write books about itself. 
                        The loop closes. The story continues.
                    </p>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Birth of AI Era -->
    <div class="era-separator">
        <h2 class="era-title">The Birth of Artificial Intelligence</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1942</span>
                    <h3 class="timeline-title">Asimov's Three Laws of Robotics</h3>
                    <p class="timeline-description">
                        Isaac Asimov introduces the Three Laws in "Runaround": robots must not harm humans, must obey orders, and must preserve themselves. 
                        These fictional laws profoundly influence real AI ethics discussions for decades.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for AI ethics debates</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1943</span>
                    <h3 class="timeline-title">McCulloch-Pitts Neuron</h3>
                    <p class="timeline-description">
                        Warren McCulloch and Walter Pitts publish "A Logical Calculus of Ideas Immanent in Nervous Activity," 
                        creating the first mathematical model of artificial neurons. This bridges biology and computation.
                    </p>
                    <div class="timeline-tech">Innovation: First artificial neuron model</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1948</span>
                    <h3 class="timeline-title">Wiener's Cybernetics</h3>
                    <p class="timeline-description">
                        Norbert Wiener publishes "Cybernetics: Or Control and Communication in the Animal and the Machine," 
                        establishing the theoretical framework for feedback control systems and inspiring generations of AI researchers.
                    </p>
                    <div class="timeline-tech">Impact: Foundational theory for intelligent systems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1948</span>
                    <h3 class="timeline-title">Shannon's Information Theory</h3>
                    <p class="timeline-description">
                        Claude Shannon establishes information theory, providing the mathematical framework for digital communication 
                        and establishing the bit as the fundamental unit of information.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1949</span>
                    <h3 class="timeline-title">Hebb's Rule</h3>
                    <p class="timeline-description">
                        Donald Hebb publishes "The Organization of Behavior," proposing that "neurons that fire together wire together." 
                        This principle becomes fundamental to how neural networks learn through synaptic strengthening.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for all neural network learning algorithms</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1950</span>
                    <h3 class="timeline-title">Turing Test</h3>
                    <p class="timeline-description">
                        Alan Turing proposes the "Imitation Game" in "Computing Machinery and Intelligence," 
                        establishing a practical test for machine intelligence and the philosophical framework that guides AI research.
                    </p>
                    <div class="timeline-tech">Legacy: Defined the goal of conversational AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1951</span>
                    <h3 class="timeline-title">SNARC - First Neural Network Machine</h3>
                    <p class="timeline-description">
                        Marvin Minsky creates the Stochastic Neural Analog Reinforcement Calculator, the first artificial neural network machine. 
                        Built with vacuum tubes, it simulates a rat finding its way through a maze using 40 artificial neurons.
                    </p>
                    <div class="timeline-tech">Components: Vacuum tubes, adjustable knobs for memory</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1952</span>
                    <h3 class="timeline-title">Grace Hopper's First Compiler</h3>
                    <p class="timeline-description">
                        Grace Hopper develops the A-0 compiler, the first program to translate human-readable code into machine language. 
                        This breakthrough enables higher-level programming languages essential for AI development.
                    </p>
                    <div class="timeline-tech">Legacy: Made programming accessible, enabling AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1952-59</span>
                    <h3 class="timeline-title">Arthur Samuel's Machine Learning</h3>
                    <p class="timeline-description">
                        Creates a checkers-playing program that improves through self-play. 
                        Coins the term "machine learning" in 1959 and demonstrates that computers can learn from experience.
                    </p>
                    <div class="timeline-tech">Achievement: First self-learning program</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1953</span>
                    <h3 class="timeline-title">Bellman Equations</h3>
                    <p class="timeline-description">
                        Richard Bellman publishes "An Introduction to the Theory of Dynamic Programming," establishing the mathematical foundation 
                        for reinforcement learning and optimal control theory that remains central to AI today.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of modern reinforcement learning</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1956</span>
                    <h3 class="timeline-title">Dartmouth Conference - Birth of AI</h3>
                    <p class="timeline-description">
                        Organized by McCarthy, Minsky, Shannon, and Rochester. Formally establishes AI as a field with the goal to 
                        "simulate every aspect of learning or any other feature of intelligence." The Logic Theorist, first AI program, is presented.
                    </p>
                    <div class="timeline-tech">Significance: AI becomes an academic discipline</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1957</span>
                    <h3 class="timeline-title">Perceptron</h3>
                    <p class="timeline-description">
                        Frank Rosenblatt develops the Perceptron, the first practical neural network with learning capability 
                        through adjustable weights and error-based learning. Built as a hardware machine, not just theory.
                    </p>
                    <div class="timeline-tech">Innovation: First implemented learning algorithm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1957</span>
                    <h3 class="timeline-title">General Problem Solver</h3>
                    <p class="timeline-description">
                        Newell and Simon create GPS, using abstract problem representation and flexible operators 
                        to tackle problems across various domains, unlike the domain-specific Logic Theorist.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1958</span>
                    <h3 class="timeline-title">LISP Programming Language</h3>
                    <p class="timeline-description">
                        John McCarthy creates LISP, which becomes the dominant programming language for AI development 
                        for the next several decades.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1958</span>
                    <h3 class="timeline-title">Mechanisation of Thought Processes Conference</h3>
                    <p class="timeline-description">
                        First international AI conference in England predates even the term "artificial intelligence." 
                        Brings together early pioneers and establishes international collaboration in the field.
                    </p>
                    <div class="timeline-tech">Significance: AI becomes international</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1959</span>
                    <h3 class="timeline-title">MIT AI Lab Founded</h3>
                    <p class="timeline-description">
                        Marvin Minsky and John McCarthy establish the MIT AI Lab, creating one of the twin pillars 
                        of American AI research that would train generations of AI researchers.
                    </p>
                    <div class="timeline-tech">Impact: Legitimized AI as academic discipline</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1959</span>
                    <h3 class="timeline-title">Selfridge's Pandemonium</h3>
                    <p class="timeline-description">
                        Oliver Selfridge proposes the Pandemonium architecture for pattern recognition, 
                        using parallel processing "demons" that inspired later neural network designs.
                    </p>
                    <div class="timeline-tech">Innovation: Early parallel processing concept</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1960</span>
                    <h3 class="timeline-title">ADALINE/MADALINE</h3>
                    <p class="timeline-description">
                        Widrow & Hoff introduce continuous outputs and the least-mean-square learning rule, 
                        providing more robust learning than the perceptron.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1960s</span>
                    <h3 class="timeline-title">John Holland's Genetic Algorithms</h3>
                    <p class="timeline-description">
                        Develops evolutionary computation inspired by natural selection. Genetic algorithms 
                        evolve solutions through mutation, crossover, and selection, pioneering bio-inspired AI.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of evolutionary computing</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1963</span>
                    <h3 class="timeline-title">Stanford AI Lab Founded</h3>
                    <p class="timeline-description">
                        John McCarthy establishes SAIL after leaving MIT, creating the second pillar 
                        of American AI research and fostering West Coast AI innovation.
                    </p>
                    <div class="timeline-tech">Notable work: Computer vision, robotics, natural language</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1964-67</span>
                    <h3 class="timeline-title">ELIZA Chatbot</h3>
                    <p class="timeline-description">
                        Joseph Weizenbaum creates ELIZA, which rephrases user input to simulate conversation. 
                        Despite its simplicity, it occasionally fools people into thinking it's human, 
                        leading to the concept of the "ELIZA Effect."
                    </p>
                    <div class="timeline-tech">Method: Pattern matching and keyword substitution</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1965</span>
                    <h3 class="timeline-title">Fuzzy Logic</h3>
                    <p class="timeline-description">
                        Lotfi Zadeh introduces fuzzy set theory, allowing degrees of truth rather than binary true/false. 
                        Revolutionizes control systems and enables AI to handle uncertainty and imprecision.
                    </p>
                    <div class="timeline-tech">Applications: Industrial control, consumer electronics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1965</span>
                    <h3 class="timeline-title">DENDRAL Expert System</h3>
                    <p class="timeline-description">
                        First expert system for identifying molecular structures. 
                        Pioneers the use of domain-specific knowledge in AI systems.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1965</span>
                    <h3 class="timeline-title">Robinson's Resolution Principle</h3>
                    <p class="timeline-description">
                        J. Alan Robinson introduces resolution-based automated theorem proving, 
                        providing a complete and mechanizable inference rule for first-order logic.
                    </p>
                    <div class="timeline-tech">Impact: Foundation of logic programming and Prolog</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1966-72</span>
                    <h3 class="timeline-title">Shakey the Robot</h3>
                    <p class="timeline-description">
                        SRI International develops Shakey, the first mobile robot to reason about its actions. 
                        Integrates computer vision, navigation, and planning in a single system, pioneering 
                        autonomous robotics.
                    </p>
                    <div class="timeline-tech">Innovations: STRIPS planner, A* search algorithm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1969</span>
                    <h3 class="timeline-title">Perceptrons Book - Beginning of AI Winter</h3>
                    <p class="timeline-description">
                        Minsky and Papert publish "Perceptrons," criticizing single-layer neural networks' limitations (like XOR problem). 
                        This effectively halts neural network research for over a decade, contributing to the first AI Winter.
                    </p>
                    <div class="timeline-tech">Impact: Neural network funding dried up until 1980s</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1970</span>
                    <h3 class="timeline-title">SHRDLU Natural Language Understanding</h3>
                    <p class="timeline-description">
                        Terry Winograd creates SHRDLU, demonstrating sophisticated natural language understanding in a limited "blocks world" domain. 
                        Shows AI can understand context and execute complex commands.
                    </p>
                    <div class="timeline-tech">Innovation: Context-aware language processing</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- AI Winter and Revival Era -->
    <div class="era-separator">
        <h2 class="era-title">AI Winter and Neural Network Revival</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1970</span>
                    <h3 class="timeline-title">Seppo Linnainmaa's Automatic Differentiation</h3>
                    <p class="timeline-description">
                        Develops the "reverse mode of automatic differentiation" for analyzing computational rounding errors. 
                        This mathematical foundation would later become backpropagation.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1973</span>
                    <h3 class="timeline-title">LUNAR Natural Language System</h3>
                    <p class="timeline-description">
                        William Woods creates LUNAR for NASA, answering questions about moon rock samples brought back by Apollo. 
                        Achieves 90% accuracy on geologists' questions, proving practical NLP applications.
                    </p>
                    <div class="timeline-tech">Innovation: Domain-specific question answering</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1973-80</span>
                    <h3 class="timeline-title">First AI Winter</h3>
                    <p class="timeline-description">
                        DARPA cuts AI funding after Lighthill Report criticizes AI's failure to handle "combinatorial explosion." 
                        Combined with Minsky's critique of perceptrons, research stagnates. Many influential researchers quit the field.
                    </p>
                    <div class="timeline-tech">Causes: Overpromises, computational limitations, theoretical roadblocks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1974</span>
                    <h3 class="timeline-title">Paul Werbos - Backpropagation Discovery</h3>
                    <p class="timeline-description">
                        Discovers backpropagation algorithm in his PhD thesis, but it remains largely unnoticed 
                        until popularized by Rumelhart, Hinton, and Williams in 1986.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1976</span>
                    <h3 class="timeline-title">Physical Symbol System Hypothesis</h3>
                    <p class="timeline-description">
                        Allen Newell and Herbert Simon formally propose that "a physical symbol system has the necessary and sufficient means 
                        for general intelligent action." This hypothesis dominates AI research for decades, though later challenged by embodied cognition.
                    </p>
                    <div class="timeline-tech">Impact: Defined symbolic AI paradigm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1976</span>
                    <h3 class="timeline-title">MYCIN Expert System</h3>
                    <p class="timeline-description">
                        Stanford's MYCIN diagnoses blood infections with accuracy matching human specialists. 
                        First AI system to demonstrate expert-level performance in medicine, though never deployed due to ethical concerns.
                    </p>
                    <div class="timeline-tech">Impact: Proved AI could match human expertise in specific domains</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1976</span>
                    <h3 class="timeline-title">HARPY Speech Recognition</h3>
                    <p class="timeline-description">
                        Carnegie Mellon's HARPY achieves 1,011-word vocabulary with 95% accuracy, 
                        first system to meet DARPA's ambitious speech understanding goals.
                    </p>
                    <div class="timeline-tech">Method: Beam search through pronunciation graph</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1978</span>
                    <h3 class="timeline-title">GRASP Lab Founded by Ruzena Bajcsy</h3>
                    <p class="timeline-description">
                        Ruzena Bajcsy establishes the GRASP Lab at Penn, developing the concept of "active perception" 
                        in robotics and advancing computer vision research.
                    </p>
                    <div class="timeline-tech">Innovation: Active perception in robotics</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1979</span>
                    <h3 class="timeline-title">Kunihiko Fukushima's Neocognitron</h3>
                    <p class="timeline-description">
                        Japanese researcher Kunihiko Fukushima develops the Neocognitron, the first multilayer convolutional neural network 
                        with hierarchical feature extraction, presaging modern CNNs by decades.
                    </p>
                    <div class="timeline-tech">Innovation: First CNN architecture</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1980</span>
                    <h3 class="timeline-title">John Searle's Chinese Room</h3>
                    <p class="timeline-description">
                        Philosopher John Searle publishes "Minds, Brains, and Programs" introducing the Chinese Room thought experiment. 
                        Argues that computers manipulating symbols cannot truly understand, challenging strong AI claims.
                    </p>
                    <div class="timeline-tech">Impact: Most influential critique of computational consciousness</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1980</span>
                    <h3 class="timeline-title">Belle Chess Computer</h3>
                    <p class="timeline-description">
                        Bell Labs' Belle becomes first chess computer to achieve master rating. 
                        Custom hardware evaluates 160,000 positions per second, paving way for Deep Blue.
                    </p>
                    <div class="timeline-tech">Innovation: Specialized chess hardware</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1980s</span>
                    <h3 class="timeline-title">Expert Systems Boom - XCON</h3>
                    <p class="timeline-description">
                        Digital Equipment Corporation's XCON checks computer component compatibility, 
                        saving $25 million annually. Sparks expert system boom, demonstrating commercial AI viability.
                    </p>
                    <div class="timeline-tech">Lesson: Early commercial AI success</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1982</span>
                    <h3 class="timeline-title">Hopfield Networks</h3>
                    <p class="timeline-description">
                        John Hopfield creates networks with associative memory using energy-based dynamics. 
                        Can retrieve complete patterns from partial or noisy inputs. Marks the beginning of neural network revival.
                    </p>
                    <div class="timeline-tech">Innovation: Content-addressable memory in neural networks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1982</span>
                    <h3 class="timeline-title">Self-Organizing Maps</h3>
                    <p class="timeline-description">
                        Teuvo Kohonen develops SOMs for unsupervised learning and data visualization, 
                        inspired by how the brain organizes sensory information.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1982-92</span>
                    <h3 class="timeline-title">Japan's Fifth Generation Project</h3>
                    <p class="timeline-description">
                        Japan launches $850 million initiative to create intelligent computers using logic programming. 
                        Triggers international AI arms race with US and Europe. Despite technical achievements, 
                        fails to deliver on promises, contributing to second AI Winter.
                    </p>
                    <div class="timeline-tech">Impact: Changed global AI competition dynamics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1983</span>
                    <h3 class="timeline-title">SOAR Cognitive Architecture</h3>
                    <p class="timeline-description">
                        Laird, Newell, and Rosenbloom develop SOAR (State, Operator And Result) at CMU. 
                        A unified theory of cognition that models human problem-solving and learning through 
                        production rules and chunking. Still actively used for AI research today.
                    </p>
                    <div class="timeline-tech">Applications: Robotics, game AI, cognitive modeling</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1984</span>
                    <h3 class="timeline-title">CART Algorithm</h3>
                    <p class="timeline-description">
                        Breiman et al. introduce Classification and Regression Trees, 
                        providing a versatile tool for both classification and regression tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1984-present</span>
                    <h3 class="timeline-title">Cyc Project</h3>
                    <p class="timeline-description">
                        Doug Lenat launches ambitious effort to manually encode common sense knowledge. 
                        After 40 years and millions of assertions, highlights the difficulty of explicit knowledge representation 
                        that modern LLMs now learn implicitly.
                    </p>
                    <div class="timeline-tech">Lesson: Knowledge acquisition bottleneck</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1985</span>
                    <h3 class="timeline-title">Boltzmann Machines</h3>
                    <p class="timeline-description">
                        Hinton and Sejnowski introduce stochastic neural networks that can learn internal representations, 
                        using simulated annealing for optimization.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1985</span>
                    <h3 class="timeline-title">Connection Machine</h3>
                    <p class="timeline-description">
                        Danny Hillis develops the CM-1 with 65,536 processors working in parallel. 
                        Pioneers massively parallel computing for AI, influencing modern GPU architectures.
                    </p>
                    <div class="timeline-tech">Architecture: 65K processors, SIMD design</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1986</span>
                    <h3 class="timeline-title">Backpropagation Popularized</h3>
                    <p class="timeline-description">
                        Rumelhart, Hinton, and Williams publish "Learning Representations by Back-Propagating Errors" in Nature. 
                        Demonstrates that multi-layer networks can be effectively trained, overcoming the XOR problem 
                        and reigniting interest in neural networks.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for all modern deep learning</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1986</span>
                    <h3 class="timeline-title">Recurrent Neural Networks (RNNs)</h3>
                    <p class="timeline-description">
                        David Rumelhart refines Hopfield Networks into modern RNNs for sequence processing. 
                        Still used today for language translation, speech recognition, and NLP tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1986</span>
                    <h3 class="timeline-title">Subsumption Architecture</h3>
                    <p class="timeline-description">
                        Rodney Brooks at MIT introduces behavior-based robotics, rejecting symbolic AI for reactive systems. 
                        Enables robots to operate in real-world environments, revolutionizing robotics.
                    </p>
                    <div class="timeline-tech">Philosophy: Intelligence without representation</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1987</span>
                    <h3 class="timeline-title">NeurIPS Conference Founded</h3>
                    <p class="timeline-description">
                        First Neural Information Processing Systems conference held in Denver. 
                        Becomes the premier venue for machine learning research, now with 15,000+ attendees annually.
                    </p>
                    <div class="timeline-tech">Impact: Created global ML research community</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1987</span>
                    <h3 class="timeline-title">Adaptive Resonance Theory</h3>
                    <p class="timeline-description">
                        Grossberg and Carpenter develop ART networks that solve the stability-plasticity dilemma, 
                        allowing networks to learn new patterns without forgetting old ones.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1987-93</span>
                    <h3 class="timeline-title">Second AI Winter</h3>
                    <p class="timeline-description">
                        LISP machine market collapses overnight when standard workstations match their performance at fraction of cost. 
                        Expert systems prove brittle and expensive. Over 300 AI companies fail. 
                        Overpromises again lead to disillusionment.
                    </p>
                    <div class="timeline-tech">Lesson: Hype cycles damage long-term progress</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1988</span>
                    <h3 class="timeline-title">Moravec's Paradox</h3>
                    <p class="timeline-description">
                        Hans Moravec observes: "It is comparatively easy to make computers exhibit adult level performance on intelligence tests... 
                        and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility." 
                        This insight still shapes AI research priorities.
                    </p>
                    <div class="timeline-tech">Impact: Highlighted embodied cognition challenges</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1988</span>
                    <h3 class="timeline-title">Deep Thought Chess Computer</h3>
                    <p class="timeline-description">
                        Carnegie Mellon's Deep Thought defeats grandmaster Bent Larsen, 
                        first computer victory over grandmaster in tournament play. Precursor to Deep Blue.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1989</span>
                    <h3 class="timeline-title">Universal Approximation Theorem</h3>
                    <p class="timeline-description">
                        Cybenko proves that neural networks with one hidden layer can approximate any continuous function on compact sets. 
                        This mathematical foundation provides theoretical justification for deep learning's potential.
                    </p>
                    <div class="timeline-tech">Impact: Proved neural networks' theoretical power</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1989</span>
                    <h3 class="timeline-title">Q-Learning Algorithm</h3>
                    <p class="timeline-description">
                        Christopher Watkins introduces Q-learning in his PhD thesis "Learning from Delayed Rewards." 
                        Becomes cornerstone of reinforcement learning, enabling agents to learn optimal policies without environment models.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for game AI and robotics</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1989</span>
                    <h3 class="timeline-title">LeNet-1</h3>
                    <p class="timeline-description">
                        Yann LeCun creates the first successful convolutional neural network for handwritten digit recognition. 
                        Banks later adopt LeNet-5 for check processing.
                    </p>
                    <div class="timeline-tech">Architecture: Convolution, pooling, fully connected layers</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Rise of Modern AI Era -->
    <div class="era-separator">
        <h2 class="era-title">The Rise of Modern AI</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1990s</span>
                    <h3 class="timeline-title">Honda P Series Robots</h3>
                    <p class="timeline-description">
                        Honda develops P1, P2, and P3 humanoid robots (130-210kg), predecessors to ASIMO. 
                        Demonstrates progress in robotics and AI integration for physical tasks.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1991</span>
                    <h3 class="timeline-title">ArXiv.org Founded</h3>
                    <p class="timeline-description">
                        Paul Ginsparg launches arXiv at Los Alamos, creating the first preprint server. 
                        Revolutionizes scientific communication by enabling immediate sharing of research, 
                        accelerating AI progress through rapid dissemination of ideas.
                    </p>
                    <div class="timeline-tech">Impact: Transformed how AI research is shared globally</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1992</span>
                    <h3 class="timeline-title">TD-Gammon - Revolutionary Self-Play Learning</h3>
                    <p class="timeline-description">
                        Gerald Tesauro at IBM creates TD-Gammon using temporal difference learning. Trained entirely through self-play, 
                        it discovers opening strategies unknown to human experts, revolutionizing professional backgammon. 
                        Demonstrates that AI can surpass human knowledge through self-improvement.
                    </p>
                    <div class="timeline-tech">Architecture: 3-layer network, 198 inputs, TD(λ) algorithm</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1992</span>
                    <h3 class="timeline-title">Resilient Propagation (Rprop)</h3>
                    <p class="timeline-description">
                        Introduced as a robust training algorithm using only gradient signs, 
                        avoiding issues with gradient magnitudes in deep networks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1994</span>
                    <h3 class="timeline-title">Raj Reddy Wins Turing Award</h3>
                    <p class="timeline-description">
                        First person of Asian origin to win the Turing Award for pioneering work 
                        in speech recognition and AI systems, advancing global representation in AI.
                    </p>
                    <div class="timeline-tech">Contribution: Speech recognition, AI education</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1995</span>
                    <h3 class="timeline-title">Support Vector Machines</h3>
                    <p class="timeline-description">
                        Vapnik and Cortes formalize SVMs with the kernel trick for non-linear classification. 
                        Becomes dominant ML algorithm in late 1990s and early 2000s before deep learning.
                    </p>
                    <div class="timeline-tech">Innovation: Kernel methods for non-linear problems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1995</span>
                    <h3 class="timeline-title">LSTM Networks</h3>
                    <p class="timeline-description">
                        Hochreiter and Schmidhuber introduce Long Short-Term Memory networks to solve the vanishing gradient problem. 
                        Enables learning of long-term dependencies in sequences, revolutionizing sequence modeling.
                    </p>
                    <div class="timeline-tech">Applications: Language modeling, speech recognition, time series</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1997</span>
                    <h3 class="timeline-title">Deep Blue Defeats Kasparov</h3>
                    <p class="timeline-description">
                        IBM's Deep Blue becomes the first computer to defeat world chess champion Garry Kasparov 
                        under regular time controls. Marks a milestone in AI achieving superhuman performance in complex games.
                    </p>
                    <div class="timeline-tech">Method: Brute force search with sophisticated evaluation</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1997</span>
                    <h3 class="timeline-title">Affective Computing Founded</h3>
                    <p class="timeline-description">
                        Rosalind Picard publishes "Affective Computing," creating an entirely new field 
                        focused on giving computers the ability to recognize and respond to human emotions.
                    </p>
                    <div class="timeline-tech">Impact: Emotion AI, human-computer interaction</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1998</span>
                    <h3 class="timeline-title">LeNet-5 Deployed</h3>
                    <p class="timeline-description">
                        Banks widely adopt LeCun's LeNet-5 for automated check processing, 
                        one of the first commercial deployments of deep learning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">1999</span>
                    <h3 class="timeline-title">Sony AIBO Robot Dog</h3>
                    <p class="timeline-description">
                        First consumer AI robot pet capable of face recognition, detecting smiles, 
                        and learning tricks. Shows AI entering consumer market.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2000</span>
                    <h3 class="timeline-title">Judea Pearl's Causality</h3>
                    <p class="timeline-description">
                        Publishes "Causality: Models, Reasoning, and Inference," revolutionizing how we understand 
                        cause and effect in AI and statistics. Wins 2011 Turing Award for this work.
                    </p>
                    <div class="timeline-tech">Impact: Causal inference in AI and science</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2000s</span>
                    <h3 class="timeline-title">High-Frequency Trading AI Revolution</h3>
                    <p class="timeline-description">
                        AI algorithms transform financial markets, executing millions of trades per second. 
                        By 2010, HFT accounts for over 50% of US equity trading volume, fundamentally changing market dynamics.
                    </p>
                    <div class="timeline-tech">Impact: Millisecond advantages worth millions</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2001</span>
                    <h3 class="timeline-title">Random Forests</h3>
                    <p class="timeline-description">
                        Leo Breiman introduces Random Forests, combining bagging with random feature selection 
                        for robust ensemble learning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2002</span>
                    <h3 class="timeline-title">iRobot Roomba</h3>
                    <p class="timeline-description">
                        First successful consumer robot vacuum, demonstrating practical AI 
                        for everyday household tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2003</span>
                    <h3 class="timeline-title">Graph Neural Networks Begin</h3>
                    <p class="timeline-description">
                        Gori, Monfardini, and Scarselli introduce early GNN concepts for processing 
                        graph-structured data, later becoming crucial for social networks and molecular modeling.
                    </p>
                    <div class="timeline-tech">Impact: Foundation for modern GNN architectures</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2004</span>
                    <h3 class="timeline-title">DARPA Grand Challenge</h3>
                    <p class="timeline-description">
                        Autonomous vehicle competition spurring development in self-driving technology. 
                        No vehicle completes the course in first year, proving the difficulty of the task.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2005</span>
                    <h3 class="timeline-title">Stanley Wins DARPA Challenge</h3>
                    <p class="timeline-description">
                        Stanford's autonomous vehicle "Stanley" wins $2 million DARPA Grand Challenge, 
                        completing 132-mile desert course autonomously. Proves self-driving cars are possible.
                    </p>
                    <div class="timeline-tech">Impact: Launches autonomous vehicle revolution</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2005</span>
                    <h3 class="timeline-title">Boston Dynamics BigDog</h3>
                    <p class="timeline-description">
                        First quadruped robot capable of traversing rough terrain, carrying heavy loads. 
                        Beginning of practical legged robotics for real-world applications.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2006</span>
                    <h3 class="timeline-title">NVIDIA CUDA Platform</h3>
                    <p class="timeline-description">
                        NVIDIA releases CUDA, making GPU parallel processing accessible to developers. 
                        Creates the computational foundation that would enable the deep learning revolution.
                    </p>
                    <div class="timeline-tech">Impact: Made deep learning computationally feasible</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2006</span>
                    <h3 class="timeline-title">Netflix Prize Launches</h3>
                    <p class="timeline-description">
                        $1 million competition to improve movie recommendations advances collaborative filtering 
                        and sparks the modern era of data science competitions, inspiring platforms like Kaggle.
                    </p>
                    <div class="timeline-tech">Legacy: Democratized machine learning competitions</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2006</span>
                    <h3 class="timeline-title">Deep Learning Renaissance Begins</h3>
                    <p class="timeline-description">
                        Geoffrey Hinton et al. introduce Deep Belief Networks with layer-wise pre-training. 
                        Solves the vanishing gradient problem that had plagued deep networks, 
                        marking the beginning of the modern deep learning era.
                    </p>
                    <div class="timeline-tech">Breakthrough: Enables training of truly deep networks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2008</span>
                    <h3 class="timeline-title">Betterment Launches Robo-Advisors</h3>
                    <p class="timeline-description">
                        First robo-advisor democratizes investment management using AI algorithms. 
                        The sector will grow to manage hundreds of billions in assets.
                    </p>
                    <div class="timeline-tech">Impact: AI transforms financial services</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2008</span>
                    <h3 class="timeline-title">t-SNE Visualization</h3>
                    <p class="timeline-description">
                        Van der Maaten and Hinton introduce t-SNE for high-dimensional data visualization, 
                        becoming essential tool for understanding neural network representations.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2009</span>
                    <h3 class="timeline-title">ImageNet Dataset</h3>
                    <p class="timeline-description">
                        Fei-Fei Li creates ImageNet with 14 million labeled images across 21,000 categories. 
                        Provides the large-scale data needed to train deep neural networks effectively, catalyzing the deep learning revolution.
                    </p>
                    <div class="timeline-tech">Impact: Enabled breakthrough CNN architectures</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2010</span>
                    <h3 class="timeline-title">DeepMind Founded</h3>
                    <p class="timeline-description">
                        Demis Hassabis, Shane Legg, and Mustafa Suleyman found DeepMind, 
                        pioneering deep reinforcement learning years before AlphaGo. Google acquires for $650M in 2014.
                    </p>
                    <div class="timeline-tech">Focus: General artificial intelligence through RL</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2010</span>
                    <h3 class="timeline-title">ImageNet Challenge Begins</h3>
                    <p class="timeline-description">
                        Annual competition that would catalyze the deep learning revolution. 
                        Establishes CNNs as the dominant computer vision approach and drives rapid progress.
                    </p>
                    <div class="timeline-tech">Impact: Standardized benchmark for vision AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2010</span>
                    <h3 class="timeline-title">Theano Deep Learning Framework</h3>
                    <p class="timeline-description">
                        MILA releases Theano, one of the first frameworks for efficient deep learning. 
                        Pioneers automatic differentiation and GPU computation for neural networks.
                    </p>
                    <div class="timeline-tech">Legacy: Inspired TensorFlow and PyTorch</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Deep Learning Revolution Era -->
    <div class="era-separator">
        <h2 class="era-title">The Deep Learning Revolution</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2011</span>
                    <h3 class="timeline-title">Google Brain Founded</h3>
                    <p class="timeline-description">
                        Andrew Ng and Jeff Dean establish Google Brain. Their famous cat-recognition experiment 
                        using 16,000 processors proves the scalability of deep learning at unprecedented scale.
                    </p>
                    <div class="timeline-tech">Achievement: Unsupervised learning at scale</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2011</span>
                    <h3 class="timeline-title">IBM Watson Wins Jeopardy!</h3>
                    <p class="timeline-description">
                        Watson defeats champions Ken Jennings and Brad Rutter on national television ($77,147 vs $24,000 and $21,600). 
                        First system achieving champion-level open-domain question answering, bringing AI to mainstream attention.
                    </p>
                    <div class="timeline-tech">Architecture: 90 Power 750 servers, DeepQA software</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2012</span>
                    <h3 class="timeline-title">AlexNet Changes Everything</h3>
                    <p class="timeline-description">
                        Krizhevsky, Sutskever, and Hinton win ImageNet by huge margin using deep CNNs on GPUs. 
                        Uses ReLU activation, dropout, and data augmentation. Reduces error from 26.2% to 15.3%, 
                        sparking the deep learning boom.
                    </p>
                    <div class="timeline-tech">Key innovations: GPU training, ReLU, Dropout, parallel processing</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2012</span>
                    <h3 class="timeline-title">Dropout Regularization</h3>
                    <p class="timeline-description">
                        Hinton et al. introduce dropout, randomly deactivating neurons during training 
                        to prevent overfitting. Becomes standard technique in deep learning.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2012</span>
                    <h3 class="timeline-title">Amazon Acquires Kiva Systems</h3>
                    <p class="timeline-description">
                        $775 million acquisition transforms warehouse automation. 
                        Now over 750,000 robots operate in Amazon facilities, revolutionizing logistics.
                    </p>
                    <div class="timeline-tech">Impact: AI-powered supply chain transformation</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">Berkeley's Caffe Framework</h3>
                    <p class="timeline-description">
                        Yangqing Jia releases Caffe at Berkeley, becoming the go-to framework for computer vision research. 
                        Its model zoo concept accelerates research by enabling easy sharing of pre-trained models.
                    </p>
                    <div class="timeline-tech">Impact: Democratized deep learning for vision</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">Word2Vec Released</h3>
                    <p class="timeline-description">
                        Mikolov's team at Google releases Word2Vec, creating efficient word embeddings 
                        that revolutionize NLP by capturing semantic relationships in vector space.
                    </p>
                    <div class="timeline-tech">Innovation: "King - Man + Woman = Queen"</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">ICLR Conference Founded</h3>
                    <p class="timeline-description">
                        International Conference on Learning Representations founded by Yoshua Bengio and Yann LeCun. 
                        Becomes key venue for deep learning research with fully open review process.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2013</span>
                    <h3 class="timeline-title">Facebook AI Research (FAIR) Founded</h3>
                    <p class="timeline-description">
                        Yann LeCun joins Facebook to lead FAIR, focusing on open research. 
                        Would later develop PyTorch, now rivaling TensorFlow as preferred framework.
                    </p>
                    <div class="timeline-tech">Philosophy: Open science approach to AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">Generative Adversarial Networks (GANs)</h3>
                    <p class="timeline-description">
                        Ian Goodfellow introduces GANs: two networks competing against each other. 
                        Generator creates fake data, discriminator detects fakes. Revolutionizes generative modeling 
                        and enables unsupervised learning from raw data.
                    </p>
                    <div class="timeline-tech">Impact: Photorealistic image generation, style transfer</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">GloVe Word Embeddings</h3>
                    <p class="timeline-description">
                        Stanford researchers release Global Vectors (GloVe), competing with Word2Vec 
                        by combining global matrix factorization with local context windows.
                    </p>
                    <div class="timeline-tech">Innovation: Unified count-based and predictive methods</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">VGGNet</h3>
                    <p class="timeline-description">
                        Shows that deeper networks with small 3×3 filters outperform shallow networks 
                        with larger filters. Pushes networks to 16-19 layers.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">GoogLeNet/Inception</h3>
                    <p class="timeline-description">
                        Introduces inception modules with multi-scale processing and 1×1 convolutions 
                        for dimensionality reduction. Wins ImageNet with 22 layers.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">Sequence-to-Sequence Models</h3>
                    <p class="timeline-description">
                        Sutskever, Vinyals, and Le introduce seq2seq with encoder-decoder architecture, 
                        revolutionizing machine translation and dialogue systems.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">Gated Recurrent Units (GRU)</h3>
                    <p class="timeline-description">
                        Cho et al. simplify LSTM design while maintaining performance, 
                        making recurrent networks more efficient.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2014</span>
                    <h3 class="timeline-title">IBM TrueNorth Neuromorphic Chip</h3>
                    <p class="timeline-description">
                        IBM unveils TrueNorth with 1 million neurons consuming only 70mW, 
                        exploring brain-inspired computing architectures for extreme energy efficiency.
                    </p>
                    <div class="timeline-tech">Innovation: 5.4 billion transistors, event-driven processing</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">Google Photos Incident</h3>
                    <p class="timeline-description">
                        Google Photos' automatic tagging misclassifies Black people in deeply offensive way. 
                        Sparks industry-wide focus on bias detection and responsible AI development, 
                        leading to major changes in how tech companies approach fairness in AI.
                    </p>
                    <div class="timeline-tech">Impact: Watershed moment for AI ethics awareness</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">ResNet - Skip Connections</h3>
                    <p class="timeline-description">
                        He et al. introduce residual connections, enabling training of 100+ layer networks. 
                        Solves degradation problem where deeper networks performed worse. 
                        Wins ImageNet with 152 layers.
                    </p>
                    <div class="timeline-tech">Key insight: Learn residual functions instead of direct mappings</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">Batch Normalization</h3>
                    <p class="timeline-description">
                        Ioffe and Szegedy introduce batch normalization, stabilizing training 
                        and enabling much higher learning rates. Becomes essential for deep networks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">U-Net</h3>
                    <p class="timeline-description">
                        Ronneberger et al. create U-Net for biomedical image segmentation 
                        with encoder-decoder architecture and skip connections.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">YOLO - Real-Time Object Detection</h3>
                    <p class="timeline-description">
                        Joseph Redmon introduces "You Only Look Once," achieving real-time object detection 
                        with a single neural network pass. Revolutionizes computer vision applications.
                    </p>
                    <div class="timeline-tech">Speed: 45 FPS on GPU, enabling real-time applications</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">Keras Deep Learning Library</h3>
                    <p class="timeline-description">
                        François Chollet releases Keras, providing user-friendly API for deep learning. 
                        Later integrated into TensorFlow, democratizing neural network development.
                    </p>
                    <div class="timeline-tech">Philosophy: Deep learning for humans</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2015</span>
                    <h3 class="timeline-title">TensorFlow Released</h3>
                    <p class="timeline-description">
                        Google Brain open-sources TensorFlow on November 9, democratizing deep learning development 
                        worldwide. Becomes the most popular deep learning framework with millions of downloads.
                    </p>
                    <div class="timeline-tech">Impact: Accelerated global AI development</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Microsoft Tay Chatbot Incident</h3>
                    <p class="timeline-description">
                        Tay launched March 23, shut down within 24 hours after coordinated attacks exploit learning vulnerabilities. 
                        Chatbot begins posting inflammatory content after learning from malicious users. 
                        Major lesson in AI safety and adversarial attacks.
                    </p>
                    <div class="timeline-tech">Lesson: Unsupervised learning from public data carries risks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">ProPublica COMPAS Investigation</h3>
                    <p class="timeline-description">
                        Exposes algorithmic bias in criminal justice risk assessment, showing black defendants 
                        falsely labeled high-risk at nearly twice the rate of white defendants. 
                        Sparks debate on AI fairness.
                    </p>
                    <div class="timeline-tech">Impact: AI ethics enters public policy debate</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">DenseNet</h3>
                    <p class="timeline-description">
                        Huang et al. connect every layer to every other layer in feedforward fashion, 
                        improving gradient flow and parameter efficiency.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Intel Acquires Nervana</h3>
                    <p class="timeline-description">
                        Intel acquires deep learning startup Nervana for $400 million, signaling major chipmakers' 
                        strategic pivot to AI-specific hardware. Leads to development of Neural Network Processor chips.
                    </p>
                    <div class="timeline-tech">Impact: Traditional silicon giants enter AI chip race</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Google's TPU Announced</h3>
                    <p class="timeline-description">
                        Google reveals custom Tensor Processing Units, deployed internally since 2015. 
                        Strategic shift to custom silicon enables breakthroughs like AlphaGo.
                    </p>
                    <div class="timeline-tech">Performance: 15-30x faster than GPUs for inference</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">AlphaGo Defeats Lee Sedol</h3>
                    <p class="timeline-description">
                        DeepMind's AlphaGo defeats world champion Go player 4-1, 
                        achieving what many thought impossible for decades using deep reinforcement learning.
                    </p>
                    <div class="timeline-tech">Method: Monte Carlo tree search + deep neural networks</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">PyTorch Released</h3>
                    <p class="timeline-description">
                        Facebook AI Research releases PyTorch with dynamic computation graphs, 
                        quickly becoming researchers' preferred framework for its flexibility and Pythonic design.
                    </p>
                    <div class="timeline-tech">Innovation: Define-by-run approach</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2016</span>
                    <h3 class="timeline-title">Federated Learning Introduced</h3>
                    <p class="timeline-description">
                        Google introduces federated learning for training models on decentralized data 
                        without sharing raw information, pioneering privacy-preserving AI.
                    </p>
                    <div class="timeline-tech">Application: On-device learning for mobile keyboards</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Apple Neural Engine</h3>
                    <p class="timeline-description">
                        Apple introduces its Neural Engine in the A11 Bionic chip for iPhone X, bringing dedicated 
                        AI processing to consumer devices. Performs 600 billion operations per second, 
                        enabling Face ID and on-device machine learning.
                    </p>
                    <div class="timeline-tech">Impact: AI acceleration becomes standard in smartphones</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Google Colab Launches</h3>
                    <p class="timeline-description">
                        Google releases Colaboratory, providing free GPU access through Jupyter notebooks in the cloud. 
                        Democratizes deep learning by removing hardware barriers for students and researchers worldwide.
                    </p>
                    <div class="timeline-tech">Impact: Enabled millions to experiment with deep learning</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Transformer Architecture - "Attention Is All You Need"</h3>
                    <p class="timeline-description">
                        Vaswani et al. from Google introduce Transformers, replacing recurrence with self-attention. 
                        Enables parallelization and handling of much longer sequences. 
                        Becomes foundation for all modern language models.
                    </p>
                    <div class="timeline-tech">Impact: GPT, BERT, and entire LLM revolution</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">China's National AI Strategy</h3>
                    <p class="timeline-description">
                        China announces "New Generation AI Development Plan" on July 20, aiming for AI core industry of 1 trillion yuan by 2030. 
                        Triggers global AI competition and massive state investment.
                    </p>
                    <div class="timeline-tech">Impact: Changed global AI dynamics</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">First RLHF Paper</h3>
                    <p class="timeline-description">
                        Christiano et al. publish "Deep Reinforcement Learning from Human Preferences," 
                        introducing the technique that would later make ChatGPT possible.
                    </p>
                    <div class="timeline-tech">Innovation: Learning from human feedback at scale</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Capsule Networks</h3>
                    <p class="timeline-description">
                        Geoffrey Hinton introduces CapsNets with dynamic routing 
                        to better model hierarchical relationships in data.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2017</span>
                    <h3 class="timeline-title">Intel Loihi Neuromorphic Chip</h3>
                    <p class="timeline-description">
                        Intel announces Loihi, a neuromorphic research chip with 130,000 neurons 
                        and 130 million synapses, advancing brain-inspired computing.
                    </p>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Era of Large Models -->
    <div class="era-separator">
        <h2 class="era-title">The Era of Large Language Models</h2>
    </div>
    
    <section class="timeline-section">
        <div class="timeline-container">
            <div class="timeline-line"></div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Gender Shades Study</h3>
                    <p class="timeline-description">
                        Timnit Gebru and Joy Buolamwini expose systematic bias in commercial facial recognition, 
                        showing error rates up to 34% higher for dark-skinned women. Leads to industry-wide changes.
                    </p>
                    <div class="timeline-tech">Impact: AI ethics becomes mainstream concern</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Cambridge Analytica Scandal</h3>
                    <p class="timeline-description">
                        Facebook data of millions used for political profiling and targeted manipulation. 
                        Exposes dangers of AI-powered behavioral targeting and sparks global privacy regulations.
                    </p>
                    <div class="timeline-tech">Impact: GDPR enforcement, tech regulation momentum</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Lottery Ticket Hypothesis</h3>
                    <p class="timeline-description">
                        Jonathan Frankle and Michael Carbin discover that neural networks contain sparse subnetworks 
                        ("winning lottery tickets") that can achieve comparable accuracy when trained in isolation. 
                        Revolutionizes understanding of network pruning and efficiency.
                    </p>
                    <div class="timeline-tech">Impact: Enables extreme model compression</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Neural Tangent Kernel Theory</h3>
                    <p class="timeline-description">
                        Jacot, Gabriel, and Hongler introduce NTK theory, showing that infinitely wide neural networks 
                        behave like kernel methods during training. Provides new theoretical understanding of deep learning.
                    </p>
                    <div class="timeline-tech">Significance: Bridges deep learning and kernel methods</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">GPT-1</h3>
                    <p class="timeline-description">
                        OpenAI demonstrates unsupervised pre-training with 117M parameters. 
                        Shows that language models can be fine-tuned for various tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">BERT</h3>
                    <p class="timeline-description">
                        Google introduces bidirectional pre-training, achieving state-of-the-art 
                        on 11 NLP tasks. Shows the power of masked language modeling.
                    </p>
                    <div class="timeline-tech">Innovation: Bidirectional context understanding</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2018</span>
                    <h3 class="timeline-title">Been Kim's TCAV</h3>
                    <p class="timeline-description">
                        Develops Testing with Concept Activation Vectors at Google Brain, 
                        making neural networks more interpretable by understanding what concepts they learn.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2019</span>
                    <h3 class="timeline-title">GPT-2</h3>
                    <p class="timeline-description">
                        OpenAI scales to 1.5B parameters. Initially withheld due to misuse concerns, 
                        sparking debate about AI safety and open research.
                    </p>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2019</span>
                    <h3 class="timeline-title">Pinecone Founded - Vector Database Revolution</h3>
                    <p class="timeline-description">
                        Edo Liberty founds Pinecone, creating specialized infrastructure for vector similarity search. 
                        Public beta launches January 2021, enabling RAG applications that power modern AI.
                    </p>
                    <div class="timeline-tech">Impact: Essential infrastructure for ChatGPT-like systems</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2019</span>
                    <h3 class="timeline-title">Spot Robot Goes Commercial</h3>
                    <p class="timeline-description">
                        Boston Dynamics releases Spot for commercial use after 14 years of development, 
                        marking practical deployment of advanced legged robotics.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">Scaling Laws Paper</h3>
                    <p class="timeline-description">
                        Kaplan et al. from OpenAI discover power law relationships between model size, dataset size, 
                        and compute budget. Shows predictable improvements with scale, guiding future model development.
                    </p>
                    <div class="timeline-tech">Impact: Established roadmap for LLM scaling</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">GPT-3</h3>
                    <p class="timeline-description">
                        175B parameters demonstrate emergent few-shot learning abilities. 
                        Can perform tasks with just examples, no fine-tuning needed. 
                        Marks shift to foundation models.
                    </p>
                    <div class="timeline-tech">Breakthrough: In-context learning emerges</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">Vision Transformer (ViT)</h3>
                    <p class="timeline-description">
                        Dosovitskiy et al. apply transformers directly to image patches, 
                        showing convolutions aren't necessary for vision tasks.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">AlphaFold 2 Solves Protein Folding</h3>
                    <p class="timeline-description">
                        DeepMind's AlphaFold achieves atomic-level accuracy in protein structure prediction, 
                        solving a 50-year-old grand challenge in biology. Wins 2024 Nobel Prize in Chemistry.
                    </p>
                    <div class="timeline-tech">Impact: Revolutionizes drug discovery and biology</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2020</span>
                    <h3 class="timeline-title">Timnit Gebru Fired from Google</h3>
                    <p class="timeline-description">
                        Google fires AI ethics researcher on December 2 over "Stochastic Parrots" paper critiquing large language models. 
                        2,700+ employees protest. Raises questions about corporate control over AI ethics research.
                    </p>
                    <div class="timeline-tech">Impact: Major turning point in AI ethics debate</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">"Stochastic Parrots" Paper Published</h3>
                    <p class="timeline-description">
                        Bender, Gebru, McMillan-Major, and Mitchell publish landmark critique of LLMs, 
                        warning about environmental costs, bias amplification, and illusions of understanding.
                    </p>
                    <div class="timeline-tech">Legacy: Term becomes standard LLM critique</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">CLIP</h3>
                    <p class="timeline-description">
                        OpenAI aligns vision and language representations through contrastive learning 
                        on 400M image-text pairs. Enables zero-shot image classification.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">DALL-E</h3>
                    <p class="timeline-description">
                        OpenAI demonstrates text-to-image generation using discrete VAE and autoregressive transformer. 
                        Shows AI can create novel visual concepts.
                    </p>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">Liquid Neural Networks</h3>
                    <p class="timeline-description">
                        MIT researchers introduce networks inspired by C. elegans neurons that can adapt 
                        their behavior after training, potentially solving catastrophic forgetting.
                    </p>
                    <div class="timeline-tech">Innovation: Time-continuous, adaptive networks</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">GitHub Copilot Launches</h3>
                    <p class="timeline-description">
                        Technical preview released June 29 based on OpenAI Codex. First widely-adopted AI coding assistant, 
                        transforming software development. General availability June 2022, now used by millions.
                    </p>
                    <div class="timeline-tech">Controversy: Copyright concerns over training on public code</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">Anthropic Founded</h3>
                    <p class="timeline-description">
                        Former OpenAI researchers led by Dario and Daniela Amodei found Anthropic, 
                        focusing on AI safety and building "helpful, harmless, and honest" AI systems.
                    </p>
                    <div class="timeline-tech">Mission: Steerable, interpretable, and safe AI</div>
                </div>
            </div>
            
            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2021</span>
                    <h3 class="timeline-title">UNESCO AI Ethics Framework</h3>
                    <p class="timeline-description">
                        193 countries adopt first global agreement on AI ethics, 
                        establishing principles for responsible AI development worldwide.
                    </p>
                    <div class="timeline-tech">Scope: Human rights, transparency, accountability</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot major"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">Chain-of-Thought Prompting Discovered</h3>
                    <p class="timeline-description">
                        Jason Wei et al. at Google publish breakthrough showing that providing reasoning steps dramatically improves 
                        large model performance. GSM8K math accuracy jumps from 17.9% to 56.9%.
                    </p>
                    <div class="timeline-tech">Impact: Revolutionized how we interact with LLMs</div>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-dot"></div>
                <div class="timeline-content">
                    <span class="timeline-date">2022</span>
                    <h3 class="timeline-title">InstructGPT and RLHF</h3>
                    <p class="timeline-description">
                        OpenAI shows that 1.3B parameter InstructGPT is preferred over 175B GPT-3 thanks to RLHF. 
                        Demonstrates that alignment matters more than scale.
                    </p>
                    <div class="timeline-tech">Breakthrough: Human feedback improves AI behavior</div>
